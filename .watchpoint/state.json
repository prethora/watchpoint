[
  {
    "title": "Phase 1: Foundation Code Structure",
    "description": "Initialize the repository and implement the static code structures that serve as the contract for the entire system. This involves setting up the Go module layout, translating `01-foundation-types.md` into Go structs and interfaces, and implementing the Configuration loader from `03-config.md`. This phase establishes the strict typing, error constants, and environment variable parsing logic required before any database or API logic can be written. Definition of Done: The project compiles, `types` package is importable, and the Config loader passes unit tests with mock environment variables.",
    "subItems": [
      {
        "task": "Initialize Go Module and Dependencies",
        "actor": "AI",
        "description": "Initialize the Go module `watchpoint` in the root directory, strictly specifying Go version `1.21` or higher. Add the required dependencies defined in the Tech Stack and Foundation documents. Specifically: `github.com/go-chi/chi/v5` (router prep), `github.com/jackc/pgx/v5` (driver prep), `github.com/kelseyhightower/envconfig` (config loading), `github.com/go-playground/validator/v10` (validation tags), `github.com/joho/godotenv` (local dev), `github.com/aws/aws-sdk-go-v2` (root SDK), and `github.com/google/uuid` (ID generation). Run `go mod tidy`.",
        "priority": "Critical",
        "relevant_files": [
          "watchpoint-tech-stack-v3.3.md (Section 4.1)"
        ],
        "relevant_flows": [],
        "definition_of_done": "`go.mod` exists with `go 1.21+`. Dependencies are pinned. `go list -m all` runs without error.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-05T22:50:30.566309+00:00",
        "completed_at": "2026-02-05T22:54:28.774757+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Scaffold Project Directory Structure",
        "actor": "AI",
        "description": "Create the directory tree exactly as specified in the Tech Stack document. Create empty placeholder directories for `cmd/api`, `cmd/batcher`, `cmd/data-poller`, `cmd/eval-worker`, `cmd/email-worker`, `cmd/webhook-worker`, `cmd/archiver`. Create `internal/types`, `internal/config`, `internal/db`, `migrations/`, and `runpod/`. Do not create main.go files yet.",
        "priority": "Critical",
        "relevant_files": [
          "watchpoint-tech-stack-v3.3.md (Section 13)"
        ],
        "relevant_flows": [],
        "definition_of_done": "Directory structure matches the documentation. `tree` command output confirms layout.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-05T22:54:28.775121+00:00",
        "completed_at": "2026-02-05T22:56:13.130031+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Implement Core Domain Types and Interfaces",
        "actor": "AI",
        "description": "Create `internal/types/domain.go` for core entities (`WatchPoint`, `Organization`, `User`). Create `internal/types/enums.go` for constants (`Status`, `ForecastType`). Create `internal/types/interfaces.go` for Core Interfaces (`RepositoryRegistry`, `NotificationChannel`). Ensure all structs include the specified JSON and DB tags.",
        "priority": "Critical",
        "relevant_files": [
          "01-foundation-types.md (Section 2, 4, 6)"
        ],
        "relevant_flows": [
          "WPLC-001"
        ],
        "definition_of_done": "Code compiles. Core entities and interfaces are exported.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-05T22:56:13.130158+00:00",
        "completed_at": "2026-02-05T23:04:26.001293+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Implement Hoisted DTOs (Shared Types)",
        "actor": "AI",
        "description": "Create `internal/types/dtos.go` (or append to `domain.go`). Implement the 'Hoisted Types' defined in Section 10. This is critical for worker interoperability. Must include: `NotificationPayload`, `MonitorSummary`, `Billing` types, `Auth` types, and `VerificationResult`. These serve as the contract between the API and Workers.",
        "priority": "Critical",
        "relevant_files": [
          "01-foundation-types.md (Section 10)"
        ],
        "relevant_flows": [
          "NOTIF-001",
          "BILL-001"
        ],
        "definition_of_done": "All types from Section 10 are implemented with correct JSON tags.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-05T23:04:26.001798+00:00",
        "completed_at": "2026-02-05T23:08:40.411517+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Implement Error Handling Infrastructure",
        "actor": "AI",
        "description": "Create `internal/types/errors.go`. Define the `AppError` struct, the `ErrorCode` string type, and the complete list of error constants (e.g., `ErrValidationInvalidLat`). Implement the `Error() string` interface method for `AppError` to ensure it integrates with standard Go error handling.",
        "priority": "High",
        "relevant_files": [
          "01-foundation-types.md (Section 7, 12.1)"
        ],
        "relevant_flows": [
          "WPLC-012"
        ],
        "definition_of_done": "Code compiles. All error codes from the document are present as constants.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-05T23:08:40.411790+00:00",
        "completed_at": "2026-02-05T23:14:28.564168+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Implement Telemetry and Event Structures",
        "actor": "AI",
        "description": "Create `internal/types/telemetry.go` and `internal/types/events.go`. Define the constant strings for Metrics (`MetricForecastReady`, etc.), Event Types (`EventThresholdCrossed`), and Zarr Schema Variables (`ZarrVarTemperatureC` from Section 12.3). Crucially, define the `EventEnvelope` and `EvalMessage` structs here (from Section 10.7) to standardize event payloads.",
        "priority": "Normal",
        "relevant_files": [
          "01-foundation-types.md (Section 4.4, 10.7, 12.2, 12.3)"
        ],
        "relevant_flows": [
          "OBS-010",
          "EVAL-001"
        ],
        "definition_of_done": "Constants and `EventEnvelope` struct are defined and exported.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-05T23:14:28.564418+00:00",
        "completed_at": "2026-02-05T23:17:07.985091+00:00",
        "satisfaction_iterations": 2,
        "skip_reason": null
      },
      {
        "task": "Implement Secure Types (SecretString)",
        "actor": "AI",
        "description": "Create `internal/types/secure.go`. Define the `SecretString` type. Implement `String()` and `MarshalJSON()` methods to return `***REDACTED***`. Implement a unit test `internal/types/secret_test.go` that verifies `fmt.Sprintf` and `json.Marshal` do not leak the raw value.",
        "priority": "Critical",
        "relevant_files": [
          "03-config.md (Section 2.3)"
        ],
        "relevant_flows": [
          "SEC-005"
        ],
        "definition_of_done": "`go test ./internal/types` passes. Test confirms redaction works.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-05T23:17:07.985366+00:00",
        "completed_at": "2026-02-05T23:19:28.326470+00:00",
        "satisfaction_iterations": 2,
        "skip_reason": null
      },
      {
        "task": "Implement JSONB Serialization Helpers",
        "actor": "AI",
        "description": "Create `internal/types/jsonb.go`. Implement `sql.Scanner` and `driver.Valuer` interfaces for complex struct types stored as JSONB (e.g., `Conditions`, `ChannelList`, `MonitorConfig`). This is required for Phase 2 DB integration.",
        "priority": "High",
        "relevant_files": [
          "01-foundation-types.md (Section 3)"
        ],
        "relevant_flows": [
          "WPLC-001"
        ],
        "definition_of_done": "Methods `Scan` and `Value` exist for the specified types. Code compiles.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-05T23:19:28.326755+00:00",
        "completed_at": "2026-02-05T23:23:31.848806+00:00",
        "satisfaction_iterations": 2,
        "skip_reason": null
      },
      {
        "task": "Implement Domain Validation Logic",
        "actor": "AI",
        "description": "Create `internal/types/validation.go`. Implement the pure functions defined in the spec: `IsCONUS(lat, lon)`, `ValidateWebhookURL(url)`, `ValidateTimeWindow`, and the `StandardVariables` map registry. Note: Do not implement the `Validator` struct registry yet (Phase 4), just the logic functions.",
        "priority": "High",
        "relevant_files": [
          "01-foundation-types.md (Section 5, 11, 14)"
        ],
        "relevant_flows": [
          "VALID-001",
          "API-002"
        ],
        "definition_of_done": "Functions are implemented. `StandardVariables` map is populated.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-05T23:23:31.849077+00:00",
        "completed_at": "2026-02-05T23:27:12.972504+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Implement Context Management Helpers",
        "actor": "AI",
        "description": "Create `internal/types/context.go`. Define unexported `contextKey` types to prevent collision. Implement and export `WithActor`/`GetActor`, `WithLogger`/`GetLogger`, etc. This establishes the pattern for request-scoped data passing.",
        "priority": "High",
        "relevant_files": [
          "01-foundation-types.md (Section 8)"
        ],
        "relevant_flows": [
          "API-001"
        ],
        "definition_of_done": "Context keys are private. Helper functions are public and compile.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-05T23:27:12.972887+00:00",
        "completed_at": "2026-02-05T23:29:42.187916+00:00",
        "satisfaction_iterations": 2,
        "skip_reason": null
      },
      {
        "task": "Implement Cross-Language Contract Test",
        "actor": "AI",
        "description": "Create `internal/types/contract_test.go`. This test must instantiate `EvalMessage` (from events.go) and `NotificationPayload` (from dtos.go) structs, marshal them to JSON, and assert that the keys are strictly `snake_case` as required by the Python worker contract.",
        "priority": "Normal",
        "relevant_files": [
          "01-foundation-types.md (Section 13)"
        ],
        "relevant_flows": [
          "EVAL-001"
        ],
        "definition_of_done": "`go test ./internal/types` passes. Test fails if struct tags are missing or incorrect.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-05T23:29:42.188306+00:00",
        "completed_at": "2026-02-05T23:33:04.306079+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Define Configuration Structs",
        "actor": "AI",
        "description": "Create `internal/config/config.go`. Define the global `Config` struct and all nested structs (`ServerConfig`, `DatabaseConfig`, `AWSConfig`, etc.) exactly as specified in `03-config.md`. Ensure all `envconfig` and `validate` struct tags are applied correctly.",
        "priority": "Critical",
        "relevant_files": [
          "03-config.md (Section 2)"
        ],
        "relevant_flows": [],
        "definition_of_done": "Structs match the architecture document. Code compiles.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-05T23:33:04.306180+00:00",
        "completed_at": "2026-02-05T23:37:02.420856+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Implement Configuration Interfaces and Build Info",
        "actor": "AI",
        "description": "Create `internal/config/interfaces.go` defining `SecretProvider`. Create `internal/config/build.go` defining the `BuildInfo` struct and global variables (`version`, `commit`) for linker injection.",
        "priority": "High",
        "relevant_files": [
          "03-config.md (Section 5.1, 8.1)"
        ],
        "relevant_flows": [],
        "definition_of_done": "Interface and globals are defined and exported.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-05T23:37:02.421119+00:00",
        "completed_at": "2026-02-05T23:38:56.510704+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Implement Secret Providers (Env & SSM Stub)",
        "actor": "AI",
        "description": "Create `internal/config/provider_env.go` implementing `EnvVarProvider` using `os.LookupEnv`. Create `internal/config/provider_ssm.go` defining `SSMProvider` struct with a stubbed `GetParametersBatch` method (returning empty map/error for now) to satisfy the interface without heavy logic.",
        "priority": "High",
        "relevant_files": [
          "03-config.md (Section 5.1)"
        ],
        "relevant_flows": [],
        "definition_of_done": "Both structs satisfy the `SecretProvider` interface.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-05T23:38:56.510984+00:00",
        "completed_at": "2026-02-05T23:41:20.565317+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Implement Config Loader Logic",
        "actor": "AI",
        "description": "Create `internal/config/loader.go`. Implement `LoadConfig(provider)`. Use `godotenv.Load()` to support local `.env` files. Use `envconfig` to process the struct tags. Implement the logic to scan for `_SSM_PARAM` suffix variables and resolve them via the provider if not `APP_ENV=local`. Finally, run the `validator` against the populated struct.",
        "priority": "Critical",
        "relevant_files": [
          "03-config.md (Section 5.2)"
        ],
        "relevant_flows": [],
        "definition_of_done": "Loader compiles. Logic handles hybrid resolution and validation.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-05T23:41:20.565590+00:00",
        "completed_at": "2026-02-05T23:50:11.818178+00:00",
        "satisfaction_iterations": 2,
        "skip_reason": null
      },
      {
        "task": "Test Config Loading Strategy",
        "actor": "AI",
        "description": "Create `internal/config/loader_test.go`. Test 1: Verify `envconfig` tags map correctly using `os.Setenv`. Test 2: Verify `_SSM_PARAM` resolution logic calls the mock provider. Test 3: Verify `.env` file loading (create temp file).",
        "priority": "Critical",
        "relevant_files": [
          "03-config.md (Section 6.2)"
        ],
        "relevant_flows": [],
        "definition_of_done": "`go test ./internal/config` passes.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-05T23:50:11.818295+00:00",
        "completed_at": "2026-02-05T23:57:22.141404+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Create Root Makefile",
        "actor": "AI",
        "description": "Create a `Makefile` in the root. Add targets: `test` (runs `go test ./...`), `build` (runs `go build ./cmd/...` to verify import paths), `clean`. This standardizes the verification step.",
        "priority": "Normal",
        "relevant_files": [],
        "relevant_flows": [],
        "definition_of_done": "`make test` runs and passes all tests created in this phase.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-05T23:57:22.141912+00:00",
        "completed_at": "2026-02-05T23:59:39.074388+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      }
    ],
    "status": "complete",
    "phase_completed_at": "2026-02-05T23:59:39.074638+00:00",
    "phase_verification": "PASS: go build ./... succeeded. go test ./... passed (internal/config, internal/types)."
  },
  {
    "title": "Phase 2: Local Infrastructure Scaffolding",
    "description": "Stand up the local development environment using `docker-compose` as defined in `12-operations.md`. This includes configuring PostgreSQL (Supabase simulation), LocalStack (SQS/S3/SSM), and MinIO. Crucially, this phase implements the database schema from `02-foundation-db.md` by writing and applying all SQL migration files (`up.sql`). Definition of Done: `docker-compose up` starts all services, migrations apply successfully, and a basic Go `main.go` can connect to the local database and ping LocalStack.",
    "subItems": [
      {
        "task": "Create Docker Compose Configuration",
        "actor": "AI",
        "description": "Create `docker-compose.yml` in the root. Define 4 services: `postgres` (Image: postgres:15, Port: 5432), `localstack` (Image: localstack/localstack, Port: 4566, Services: sqs,ssm,events), `minio` (Image: minio/minio, Ports: 9000/9001), and `setup` (Image: amazon/aws-cli). \n\nCRITICAL REQUIREMENTS:\n1. Define a top-level `networks` key: `networks: { default: { name: watchpoint_net } }` to ensure deterministic networking for the Makefile.\n2. Implement strict `healthcheck` blocks for Postgres, LocalStack, and MinIO.\n3. The `setup` container must have `depends_on` with `condition: service_healthy` for all three infrastructure services.\n4. Define named **volumes** (`postgres_data`, `minio_data`) mapped to the respective containers.\n5. Mount the `./scripts` directory into the `setup` container so it can run the init script.",
        "priority": "Critical",
        "relevant_files": [
          "12-operations.md (Section 2.1, 2.2)"
        ],
        "relevant_flows": [],
        "definition_of_done": "`docker-compose config` verifies syntax. `docker-compose up -d` starts containers. `docker network ls` shows `watchpoint_net`.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T00:09:29.383088+00:00",
        "completed_at": "2026-02-06T00:11:40.018631+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Create Infrastructure Setup Script",
        "actor": "AI",
        "description": "Create `scripts/local-stack-init.sh`. This script runs *inside* the `setup` container. It must:\n1. Create S3 buckets (`watchpoint-forecasts`, `watchpoint-archive`) targeting the **MinIO** endpoint (`http://minio:9000`).\n2. Create SQS queues defined in SAM (`eval-queue-urgent`, `eval-queue-standard`, `notification-queue`, and their DLQs) targeting the **LocalStack** endpoint (`http://localstack:4566`).\n3. Populate SSM Parameters defined in `03-config.md` with dummy values (e.g., `STRIPE_SECRET_KEY`) targeting LocalStack.",
        "priority": "Critical",
        "relevant_files": [
          "12-operations.md (Section 2.2)",
          "04-sam-template.md (Section 4)",
          "03-config.md (Section 4)"
        ],
        "relevant_flows": [
          "OBS-001",
          "NOTIF-001"
        ],
        "definition_of_done": "Script exists. When run via docker-compose, logs show successful creation of buckets on MinIO and queues on LocalStack.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T00:11:53.000162+00:00",
        "completed_at": "2026-02-06T00:15:59.518102+00:00",
        "satisfaction_iterations": 2,
        "skip_reason": null
      },
      {
        "task": "Generate Migrations: Batch 1 (Foundation)",
        "actor": "AI",
        "description": "Create SQL migration files in `migrations/`. \n1. `001_extensions.up.sql` / `.down.sql`: Enable `uuid-ossp`, `cube`, `earthdistance`.\n2. `002_organizations.up.sql` / `.down.sql`: Create `organizations`, `users`, `rate_limits` tables and indexes.",
        "priority": "Critical",
        "relevant_files": [
          "02-foundation-db.md (Section 2, 3.1, 5.3, 8)"
        ],
        "relevant_flows": [
          "USER-001"
        ],
        "definition_of_done": "Files exist. SQL syntax is valid Postgres 15.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T00:16:13.243131+00:00",
        "completed_at": "2026-02-06T00:18:24.839313+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Generate Migrations: Batch 2 (Core Domain)",
        "actor": "AI",
        "description": "Create SQL migration files in `migrations/`.\n1. `003_watchpoints.up.sql` / `.down.sql`: Create `watchpoints` table. Ensure the `tile_id` generated column and `idx_watchpoints_tile_active` index are correct.\n2. `004_evaluation.up.sql` / `.down.sql`: Create `watchpoint_evaluation_state`.\n3. `005_notifications.up.sql` / `.down.sql`: Create `notifications` and `notification_deliveries`.",
        "priority": "Critical",
        "relevant_files": [
          "02-foundation-db.md (Section 3.2, 4.1, 4.2)"
        ],
        "relevant_flows": [
          "WPLC-001",
          "EVAL-001"
        ],
        "definition_of_done": "Files exist. `tile_id` logic matches spec exactly.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T00:18:39.713285+00:00",
        "completed_at": "2026-02-06T00:20:50.541872+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Generate Migrations: Batch 3 (System & Auth)",
        "actor": "AI",
        "description": "Create SQL migration files in `migrations/`.\n1. `006_system.up.sql` / `.down.sql`: Create `api_keys`, `sessions`, `security_events`, `audit_log`, `idempotency_keys`, `password_resets`.\n2. `007_forecasts.up.sql` / `.down.sql`: Create `forecast_runs`, `calibration_coefficients`, `calibration_candidates`, `verification_results`, `job_locks`, `job_history`, `usage_history`.\n3. `008_triggers.up.sql` / `.down.sql`: Create the `increment_config_version` trigger function.\n4. `099_admin_roles.up.sql` / `.down.sql`: Create the `watchpoint_support_ro` role.",
        "priority": "Critical",
        "relevant_files": [
          "02-foundation-db.md (Section 5, 6, 7)"
        ],
        "relevant_flows": [
          "FCST-001",
          "SEC-001"
        ],
        "definition_of_done": "Files exist. Trigger logic matches `02-foundation-db.md` exactly.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T00:21:03.410318+00:00",
        "completed_at": "2026-02-06T00:23:53.684347+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Implement Migration tooling in Makefile",
        "actor": "AI",
        "description": "Add targets to `Makefile`: `migrate-up` and `migrate-down`. These targets must execute a Docker container (`migrate/migrate`) attached to the `watchpoint_net` network (defined in Task 1). Do NOT rely on host-installed tools.\n\nCommand Example: `docker run --rm --network watchpoint_net -v $(PWD)/migrations:/migrations migrate/migrate -path=/migrations -database 'postgres://postgres:localdev@postgres:5432/watchpoint?sslmode=disable' up`.",
        "priority": "High",
        "relevant_files": [
          "12-operations.md (Section 2.3)"
        ],
        "relevant_flows": [],
        "definition_of_done": "`make migrate-up` successfully applies all migrations to the running Postgres container.",
        "status": "complete",
        "reports": [
          ".watchpoint/reports/architectural/phase-02_implement-migration-tooling_2026-02-06T003000.md"
        ],
        "started_at": "2026-02-06T00:24:07.035784+00:00",
        "completed_at": "2026-02-06T00:30:45.330595+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Create Environment Configs",
        "actor": "AI",
        "description": "Create `.env.example` in root. This file defines variables for the **Host** Go application to connect to the dockerized services (via localhost ports). Variables: `DATABASE_URL`, `AWS_ENDPOINT_URL` (http://localhost:9000 for S3), `SQS_ENDPOINT_URL` (http://localhost:4566), `APP_ENV=local`. Document in README that developers should copy this to `.env`.",
        "priority": "Normal",
        "relevant_files": [
          "03-config.md (Section 6.1)"
        ],
        "relevant_flows": [],
        "definition_of_done": "`.env.example` exists and matches the localhost ports mapping defined in `docker-compose.yml`.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T00:31:13.181136+00:00",
        "completed_at": "2026-02-06T00:33:29.406022+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Verify Infrastructure State",
        "actor": "AI",
        "description": "Create a verification script `scripts/verify-infra.sh`. It should: 1. Check `docker-compose ps` for health. 2. Use `docker exec` to query Postgres for table count (should be >10). 3. Use `curl` to check LocalStack SQS for queue existence. 4. Use `curl` to check MinIO health.",
        "priority": "Normal",
        "relevant_files": [],
        "relevant_flows": [],
        "definition_of_done": "Script runs and outputs 'Infrastructure Verified'.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T00:33:44.309899+00:00",
        "completed_at": "2026-02-06T00:36:31.877135+00:00",
        "satisfaction_iterations": 2,
        "skip_reason": null
      }
    ],
    "status": "complete",
    "phase_completed_at": "2026-02-06T00:36:55.875558+00:00",
    "phase_verification": "PASS: go build/test passed, docker-compose.yml valid, shell scripts syntax valid. Note: container runtime verification deferred to human (docker compose up + make migrate-up + verify-infra.sh)."
  },
  {
    "title": "Phase 3: External Service Integration (Interfaces & Mocks)",
    "description": "Implement the `10-external-integrations.md` package. This phase defines the Go interfaces for Stripe, SendGrid, and OAuth providers, and generates their Mock implementations using a mocking framework (e.g., `mockery`). While the 'real' client logic (HTTP calls) is implemented here, the primary goal is to unblock the API layer by providing testable interfaces. Definition of Done: Interfaces are defined, Mocks are generated, and unit tests verify the retry/circuit-breaker logic in the base HTTP client.",
    "subItems": [
      {
        "task": "Scaffold External Package & Implement BaseClient",
        "actor": "AI",
        "description": "Create directory `internal/external`. Implement `internal/external/client.go` defining the `BaseClient` struct. This struct must wrap `*http.Client` and a `gobreaker.CircuitBreaker`. Implement the `Do(req *http.Request)` method to: 1. Inject trace headers (if available in context), 2. Execute within the circuit breaker, 3. Implement a retry loop for 429/5xx errors using `RetryPolicy`. Map generic HTTP errors to `types.ErrUpstream*`.",
        "priority": "Critical",
        "relevant_files": [
          "10-external-integrations.md (Section 3.1, 3.2)",
          "01-foundation-types.md (Section 7)"
        ],
        "relevant_flows": [],
        "definition_of_done": "`client.go` exists. Unit test `client_test.go` using `httptest` confirms retries happen on 500s and circuit breaker opens after threshold.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T00:41:57.441834+00:00",
        "completed_at": "2026-02-06T00:49:10.458598+00:00",
        "satisfaction_iterations": 2,
        "skip_reason": null
      },
      {
        "task": "Define External Interfaces",
        "actor": "AI",
        "description": "Create `internal/external/interfaces.go`. Define all service contracts: `BillingService`, `EmailProvider`, `OAuthProvider`, `OAuthManager`, `WebhookVerifier`, and `EmailVerifier`. These must match the signatures in the architecture document exactly to ensure the API layer (Phase 5) can consume them.",
        "priority": "Critical",
        "relevant_files": [
          "10-external-integrations.md (Section 4.1, 5.1, 6.1)"
        ],
        "relevant_flows": [],
        "definition_of_done": "Code compiles. Interfaces exported.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T00:49:24.086880+00:00",
        "completed_at": "2026-02-06T00:51:49.883263+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Implement Stripe Integration",
        "actor": "AI",
        "description": "Create `internal/external/stripe.go`. Implement `StripeClient` satisfying `BillingService`. Initialize with `stripe-go` configured to use `BaseClient`. Implement `EnsureCustomer` (with search-first logic), `CreateCheckoutSession` (mapping inputs to Stripe params), `CreatePortalSession`, `GetInvoices` (mapping cursor pagination), and `GetSubscription`. Map Stripe errors (e.g., `card_declined`) to `types.AppError`.",
        "priority": "High",
        "relevant_files": [
          "10-external-integrations.md (Section 4)",
          "05e-api-billing.md (Section 4.1)"
        ],
        "relevant_flows": [
          "BILL-001",
          "BILL-002",
          "INFO-005"
        ],
        "definition_of_done": "`stripe_test.go` passes using `httptest` to mock Stripe API responses (verifying JSON parsing and error mapping).",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T00:52:03.546317+00:00",
        "completed_at": "2026-02-06T01:02:37.387019+00:00",
        "satisfaction_iterations": 2,
        "skip_reason": null
      },
      {
        "task": "Implement SendGrid Integration",
        "actor": "AI",
        "description": "Create `internal/external/sendgrid.go`. Implement `SendGridClient` satisfying `EmailProvider`. Use `sendgrid-go` (configured with `BaseClient`). Implement `Send` method mapping `types.SendInput` to SendGrid's mail v3 struct (Dynamic Templates). Map 403 response to `types.ErrEmailBlocked`.",
        "priority": "High",
        "relevant_files": [
          "10-external-integrations.md (Section 5)",
          "08b-email-worker.md (Section 4)"
        ],
        "relevant_flows": [
          "NOTIF-001"
        ],
        "definition_of_done": "`sendgrid_test.go` passes using `httptest` to verify payload structure sent to provider.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T01:02:50.602861+00:00",
        "completed_at": "2026-02-06T01:08:01.527519+00:00",
        "satisfaction_iterations": 2,
        "skip_reason": null
      },
      {
        "task": "Implement OAuth Providers",
        "actor": "AI",
        "description": "Create `internal/external/oauth.go`. Implement `GoogleProvider` and `GithubProvider` satisfying `OAuthProvider`. Implement `Exchange` method to perform two sequential calls (Token Exchange + UserInfo) using `BaseClient`. Normalize returned JSON into `types.OAuthProfile`. Implement `OAuthManager` factory to select provider by name.",
        "priority": "High",
        "relevant_files": [
          "10-external-integrations.md (Section 6)",
          "05f-api-auth.md (Section 8)"
        ],
        "relevant_flows": [
          "DASH-002"
        ],
        "definition_of_done": "`oauth_test.go` passes with `httptest` simulating token and userinfo endpoints.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T01:08:14.336242+00:00",
        "completed_at": "2026-02-06T01:13:05.975859+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Implement Webhook & Signature Verifiers",
        "actor": "AI",
        "description": "Create `internal/external/verifiers.go`. Implement `StripeVerifier` using `stripe-go/webhook` to validate signatures. Implement `SendGridVerifier` using `crypto/ecdsa` (or SDK helper if available) to verify ECDSA signatures on bounce webhooks. These methods must operate on raw byte payloads.",
        "priority": "Normal",
        "relevant_files": [
          "10-external-integrations.md (Section 4.2, 5.2)"
        ],
        "relevant_flows": [
          "BILL-007",
          "NOTIF-006"
        ],
        "definition_of_done": "Unit tests pass with sample valid/invalid payloads and signatures.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T01:13:18.496719+00:00",
        "completed_at": "2026-02-06T01:16:53.195803+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Implement Client Registry & Stubs",
        "actor": "AI",
        "description": "Create `internal/external/registry.go` and `internal/external/stubs.go`. Define `ClientRegistry` struct holding all service interfaces. Implement `NewClientRegistry(cfg)`. Logic: If `cfg.IsTestMode` is true (or APP_ENV=local), populate Registry with `Stub*` implementations (which just log actions). Otherwise, initialize real clients. This allows the app to boot locally without credentials.",
        "priority": "Critical",
        "relevant_files": [
          "10-external-integrations.md (Section 7)"
        ],
        "relevant_flows": [
          "TEST-004"
        ],
        "definition_of_done": "Unit test confirms Registry returns Stubs when config flag is set.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T01:17:05.827036+00:00",
        "completed_at": "2026-02-06T01:21:59.792146+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Generate Mocks via Makefile",
        "actor": "AI",
        "description": "Update `Makefile` with a `mocks` target: `mockery --all --case snake --outpkg mocks --output internal/external/mocks --dir internal/external`. Ensure `mockery` is available (or use `go run github.com/vektra/mockery/v2@latest`). Run the target to generate mocks for `BillingService`, `EmailProvider`, etc.",
        "priority": "Critical",
        "relevant_files": [
          "10-external-integrations.md (Section 8)"
        ],
        "relevant_flows": [],
        "definition_of_done": "`internal/external/mocks/` directory is populated with generated Go files. `make mocks` runs successfully.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T01:22:13.525869+00:00",
        "completed_at": "2026-02-06T01:25:36.340039+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      }
    ],
    "status": "complete",
    "phase_completed_at": "2026-02-06T01:25:54.928998+00:00",
    "phase_verification": "PASS: go build ./... succeeded. go test ./... passed (config, external, types). 107+ tests in external package."
  },
  {
    "title": "Phase 4: API Chassis & Middleware",
    "description": "Construct the HTTP server skeleton defined in `05a-api-core.md`. This involves setting up the `chi` router, the `Server` struct, and the complete Middleware stack (Panic Recovery, CORS, Request Logging, Auth, Rate Limiting). This phase ensures the 'pipes' of the API are functional before business logic flows through them. Definition of Done: The server starts locally, the `/health` endpoint returns 200 OK, and unknown routes return 404 with the standard error JSON format.",
    "subItems": [
      {
        "task": "Scaffold Core Package and Server Struct",
        "actor": "AI",
        "description": "Create `internal/core/server.go`. Define the `Server` struct containing dependencies: `*config.Config`, `db.RepositoryRegistry`, `*slog.Logger`, `*core.Validator` (to be created), `MetricsCollector`, and `types.SecurityService`. Implement `NewServer(...)` constructor which initializes the internal `chi` router. Implement `Handler()` method returning `http.Handler`.",
        "priority": "Critical",
        "relevant_files": [
          "05a-api-core.md (Section 3.1, 3.2)"
        ],
        "relevant_flows": [],
        "definition_of_done": "Code compiles. `Server` struct is exported.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T01:26:08.860510+00:00",
        "completed_at": "2026-02-06T01:31:37.586614+00:00",
        "satisfaction_iterations": 2,
        "skip_reason": null
      },
      {
        "task": "Implement Response and Error Utilities",
        "actor": "AI",
        "description": "Create `internal/core/response.go`. Implement:\n1. `JSON(w, r, status, data)`: Marshals data, sets Content-Type, writes status.\n2. `Error(w, r, err)`: Checks if `err` is `*types.AppError`. If so, uses its Code to determine HTTP status (e.g., `ErrValidation*` -> 400). Writes `APIErrorResponse` JSON. If generic error, returns 500.\n3. `DecodeJSON(w, r, dst)`: Decodes request body with `DisallowUnknownFields` and 1MB limit.",
        "priority": "Critical",
        "relevant_files": [
          "05a-api-core.md (Section 7)",
          "01-foundation-types.md (Section 7)"
        ],
        "relevant_flows": [
          "WPLC-012"
        ],
        "definition_of_done": "Unit tests in `response_test.go` verify correct status codes and JSON structure for various error types.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T01:31:50.247029+00:00",
        "completed_at": "2026-02-06T01:38:23.395726+00:00",
        "satisfaction_iterations": 2,
        "skip_reason": null
      },
      {
        "task": "Implement Domain Validator Wrapper",
        "actor": "AI",
        "description": "Create `internal/core/validator.go`. Define `Validator` struct wrapping `go-playground/validator`. Implement `NewValidator(logger)`. **CRITICAL:** Inside the constructor, register custom validation tags (`ssrf_url`, `is_conus`, `is_timezone`) by binding them to the pure logic functions implemented in Phase 1 (`internal/types/validation.go`). Implement `ValidateStruct` methods.",
        "priority": "High",
        "relevant_files": [
          "05a-api-core.md (Section 8)",
          "01-foundation-types.md (Section 5.2, 14)"
        ],
        "relevant_flows": [
          "VALID-001",
          "API-002"
        ],
        "definition_of_done": "Unit tests pass verifying that structs with `ssrf_url` tags fail validation when passed bad URLs.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T01:38:38.491408+00:00",
        "completed_at": "2026-02-06T01:43:56.723619+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Implement Internal Mocks for Testing",
        "actor": "AI",
        "description": "Create `internal/core/mocks.go`. Implement mock structs for `Authenticator`, `RateLimitStore`, and `SecurityService`. These mocks should allow injecting expected behaviors (e.g., `MockAuthenticator{User: ...}`) so that middleware tests can run without a database connection.",
        "priority": "High",
        "relevant_files": [],
        "relevant_flows": [],
        "definition_of_done": "Mocks satisfy their respective interfaces.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T01:44:11.887597+00:00",
        "completed_at": "2026-02-06T01:47:46.253032+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Implement Base Middleware (CORS, Panic, Metrics)",
        "actor": "AI",
        "description": "Create `internal/core/middleware_base.go`. Implement:\n1. `Recoverer`: Uses `defer recover()`. Logs stack trace. Returns 500 JSON using `core.Error()`.\n2. `RequestLogger`: Logs method, path, duration, and status. Redacts headers defined in Config.\n3. `MetricsMiddleware`: Records `APILatency` and `APIRequestCount` via the `MetricsCollector` interface (define the interface here or in `types`).\n4. `SecurityHeadersMiddleware`: Sets headers like `X-Content-Type-Options`.\n5. `NewCORSMiddleware(allowedOrigins []string)`: Handles OPTIONS preflight and sets Access-Control headers.",
        "priority": "Critical",
        "relevant_files": [
          "05a-api-core.md (Section 5.2)"
        ],
        "relevant_flows": [
          "OBS-010"
        ],
        "definition_of_done": "Middleware functions match signatures in `05a`. Tests confirm JSON error on panic and correct CORS headers.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T01:47:59.925889+00:00",
        "completed_at": "2026-02-06T01:53:30.961311+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Implement Security Middleware (IP & CSRF)",
        "actor": "AI",
        "description": "Create `internal/core/middleware_security.go`.\n1. `IPSecurityMiddleware`: Calls `SecurityService.IsIPBlocked`. If blocked, return 403 Forbidden immediate JSON.\n2. `CSRFMiddleware`: Checks if Actor is User type. If so, verifies `X-CSRF-Token` matches session. Skip for API Keys.",
        "priority": "Critical",
        "relevant_files": [
          "05a-api-core.md (Section 5.2)",
          "SEC-002"
        ],
        "relevant_flows": [
          "INFO-008"
        ],
        "definition_of_done": "Tests using `MockSecurityService` verify blocked IPs are rejected.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T01:53:43.064861+00:00",
        "completed_at": "2026-02-06T01:58:49.293911+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Implement Authentication Middleware",
        "actor": "AI",
        "description": "Create `internal/core/middleware_auth.go`. Implement `AuthMiddleware`. Logic: Extract Bearer token. Call `Authenticator` interface (inject `MockAuthenticator` for tests). If valid, create `Actor` struct and inject into context using `types.WithActor`. If invalid, return 401 JSON. Also implement `RequireRole(role)` and `RequireScope(scope)` which inspect the Actor from context.",
        "priority": "Critical",
        "relevant_files": [
          "05a-api-core.md (Section 5.2, 6.2, 6.3)"
        ],
        "relevant_flows": [
          "API-001"
        ],
        "definition_of_done": "Tests verify context injection on success and 401/403 responses on failure.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T01:59:02.975004+00:00",
        "completed_at": "2026-02-06T02:08:41.339621+00:00",
        "satisfaction_iterations": 2,
        "skip_reason": null
      },
      {
        "task": "Implement Rate Limit & Idempotency Middleware",
        "actor": "AI",
        "description": "Create `internal/core/middleware_traffic.go`.\n1. `RateLimit`: Extract OrgID from context (via `types.GetActor`). Call `RateLimitStore` interface. If over limit, return 429.\n2. `IdempotencyMiddleware`: Check `Idempotency-Key` header. Wrap `ResponseWriter` with a `ResponseCapturer` struct to buffer output. On success, call `IdempotencyRepo.Save` (interface). If key exists, return cached response.",
        "priority": "High",
        "relevant_files": [
          "05a-api-core.md (Section 5.2)",
          "API-004"
        ],
        "relevant_flows": [
          "BILL-009"
        ],
        "definition_of_done": "`ResponseCapturer` correctly buffers body. Middleware logic handles hit/miss cases.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T02:08:55.649040+00:00",
        "completed_at": "2026-02-06T02:18:10.412156+00:00",
        "satisfaction_iterations": 2,
        "skip_reason": null
      },
      {
        "task": "Implement Health Check Handler",
        "actor": "AI",
        "description": "Create `internal/core/health.go`. Implement `HandleHealth`. Logic: Create a context with 2s timeout. Launch concurrent goroutines to probe DB (`pgx.Ping`), S3 (HeadBucket), and SQS (GetQueueAttributes) using the dependencies in `Server`. Aggregate results. Return 200 OK only if all healthy.",
        "priority": "High",
        "relevant_files": [
          "05a-api-core.md (Section 9)"
        ],
        "relevant_flows": [
          "API-003",
          "FAIL-003"
        ],
        "definition_of_done": "Handler returns JSON health status. Timeouts trigger 503.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T02:18:24.320052+00:00",
        "completed_at": "2026-02-06T02:22:33.157221+00:00",
        "satisfaction_iterations": 2,
        "skip_reason": null
      },
      {
        "task": "Assemble Router and Mount Routes",
        "actor": "AI",
        "description": "Create `internal/core/routes.go`. Implement `MountRoutes()`. Chain the global middleware in strict order: Recoverer -> ContextTimeout -> RequestID -> SecurityHeaders -> Logger -> CORS -> Metrics -> IPSecurity -> Auth -> CSRF -> RateLimit -> Idempotency. Mount `/health` and `/openapi.json`. Create a `/v1` group calling `mountV1` (leave `mountV1` as a stub with a TODO comment).",
        "priority": "Critical",
        "relevant_files": [
          "05a-api-core.md (Section 4.1, 5.1)"
        ],
        "relevant_flows": [],
        "definition_of_done": "`go test` verifies the middleware chain order.",
        "status": "complete",
        "reports": [
          ".watchpoint/reports/architectural/phase-04_assemble-router_2026-02-06T023000.md"
        ],
        "started_at": "2026-02-06T02:22:46.472866+00:00",
        "completed_at": "2026-02-06T02:30:03.723070+00:00",
        "satisfaction_iterations": 2,
        "skip_reason": null
      },
      {
        "task": "Implement Main Entrypoint with Temporary Stubs",
        "actor": "AI",
        "description": "Create `cmd/api/main.go`. Wiring:\n1. Load Config (Phase 1).\n2. Initialize DB Pool (Phase 2).\n3. Initialize `Server`. **CRITICAL:** Since Phase 5 logic is missing, define temporary No-Op implementations for `Authenticator`, `RateLimitStore`, and `SecurityService` directly in `main.go` (or `wire_stubs.go`) and inject them into `NewServer`. This allows the server to compile and boot. Add `// TODO: Replace with Real Impl (Phase 5)` comments.\n4. Check `APP_ENV`.\n5. If local: `http.ListenAndServe`.\n6. If prod: `chiadapter.New` + `lambda.Start`.",
        "priority": "Critical",
        "relevant_files": [
          "05a-api-core.md (Section 1)",
          "04-sam-template.md"
        ],
        "relevant_flows": [],
        "definition_of_done": "Binary compiles. Running locally with `.env` starts HTTP server. `/health` returns 200.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T02:30:16.955051+00:00",
        "completed_at": "2026-02-06T02:34:53.419082+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      }
    ],
    "status": "complete",
    "phase_completed_at": "2026-02-06T02:35:17.102130+00:00",
    "phase_verification": "PASS: go build ./... and go test ./... all pass. 5 test packages (cmd/api, config, core, external, types). /health returns 200."
  },
  {
    "title": "Phase 5: Domain Logic Implementation",
    "description": "Implement the REST API handlers sequentially to respect internal dependencies: 1. Auth (`05f`) for actor resolution. 2. Billing (`05e`) for plan limits. 3. Organization (`05d`) for user/key management. 4. Forecasts (`05c`) for Zarr abstractions. 5. WatchPoints (`05b`) as the capstone. This phase implements the core CRUD operations, validations, and database transactions. Definition of Done: All endpoints defined in the design pass unit tests using the Mocks from Phase 3 and the Local DB from Phase 2.",
    "subItems": [
      {
        "task": "Implement Auth Foundation (Session & Security Services)",
        "actor": "AI",
        "description": "Create `internal/db/session_repo.go` and `internal/db/security_repo.go` implementing `SessionRepository` and `SecurityRepository`. Implement `internal/auth/security.go` (BruteForceProtector logic) and `internal/auth/session.go` (SessionService logic). Wire these services to use the repositories. Ensure SessionService handles CSRF token generation and validation.",
        "priority": "Critical",
        "relevant_files": [
          "05f-api-auth.md (Section 4.1, 7.2)",
          "02-foundation-db.md (Section 5.1, 5.2)"
        ],
        "relevant_flows": [
          "DASH-001",
          "SEC-001"
        ],
        "definition_of_done": "Repositories pass integration tests against Docker DB. Services pass unit tests with mocked Repos.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T02:35:32.463819+00:00",
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement Auth Core Logic (User Repo & Service)",
        "actor": "AI",
        "description": "Create `internal/db/user_repo.go` implementing `UserRepository` (GetByEmail, UpdatePassword). Create `internal/auth/service.go` implementing `AuthService`. Implement the Transactional logic for `Login` (verify hash -> update last_login -> create session -> delete expired sessions) and `AcceptInvite` (update status -> create session).",
        "priority": "Critical",
        "relevant_files": [
          "05f-api-auth.md (Section 4.1, 4.2, 7.2)",
          "02-foundation-db.md (Section 3.1)"
        ],
        "relevant_flows": [
          "USER-006",
          "USER-005"
        ],
        "definition_of_done": "`AuthService` unit tests verify transaction logic (via mocked TransactionManager). Integration tests verify User DB operations.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T02:49:54.375258+00:00",
        "completed_at": "2026-02-06T03:01:42.550370+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Implement Auth Handler",
        "actor": "AI",
        "description": "Create `internal/api/handlers/auth.go`. Implement `HandleLogin` (returns JSON + HttpOnly Cookie), `HandleLogout` (clears cookie), and `HandleOAuthCallback`. Inject `AuthService` and `SessionService`. Update `cmd/api/main.go` to replace Phase 4 stubs with these real implementations and mount routes.",
        "priority": "Critical",
        "relevant_files": [
          "05f-api-auth.md (Section 5, 6)",
          "05a-api-core.md (Section 6.2)"
        ],
        "relevant_flows": [
          "API-001",
          "DASH-004"
        ],
        "definition_of_done": "Unit tests confirm Cookie headers are set correctly. `curl` to local API `/auth/login` returns 200/401 as expected.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T03:02:02.672285+00:00",
        "completed_at": "2026-02-06T03:13:16.862309+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Implement Plan Registry",
        "actor": "AI",
        "description": "Create `internal/billing/plans.go`. Define the `PlanRegistry` interface and a concrete `StaticPlanRegistry`. Implement `GetLimits(tier)` returning hardcoded limits for Free, Starter, Pro, Business tiers as defined in the Design Addendum.",
        "priority": "High",
        "relevant_files": [
          "05e-api-billing.md (Section 4.1)",
          "watchpoint-platform-design-final.md (Billing & Plans)"
        ],
        "relevant_flows": [
          "BILL-008"
        ],
        "definition_of_done": "Interface exported. Unit test verifies all tiers return correct limits.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T03:13:35.041306+00:00",
        "completed_at": "2026-02-06T03:16:00.775541+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Implement Billing Logic & Usage Reporting",
        "actor": "AI",
        "description": "Create `internal/db/usage_repo.go` (`UsageHistoryRepo`) and `internal/db/sub_repo.go` (`SubscriptionStateRepo`). Create `internal/billing/reporter.go` implementing `UsageReporter` (and `UsageEnforcer` interface from WatchPoints). Logic: `GetCurrentUsage` must perform the **Direct Count** query against `watchpoints` table and `rate_limits` table.",
        "priority": "Critical",
        "relevant_files": [
          "05e-api-billing.md (Section 4.2, 4.4)",
          "05b-api-watchpoints.md (Section 3.2)"
        ],
        "relevant_flows": [
          "INFO-003",
          "BILL-008"
        ],
        "definition_of_done": "Integration tests verify aggregation queries against Docker DB.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T03:16:12.421211+00:00",
        "completed_at": "2026-02-06T03:24:22.708457+00:00",
        "satisfaction_iterations": 2,
        "skip_reason": null
      },
      {
        "task": "Implement Billing Handlers",
        "actor": "AI",
        "description": "Create `internal/api/handlers/billing.go`. Implement `CreateCheckoutSession`, `CreatePortalSession`, `GetUsage`. Inject `BillingService` (Stripe Client wrapper from Phase 3) and `UsageReporter`. Mount routes in `main.go`.",
        "priority": "High",
        "relevant_files": [
          "05e-api-billing.md (Section 5, 6, 8)"
        ],
        "relevant_flows": [
          "DASH-005",
          "INFO-003"
        ],
        "definition_of_done": "Handlers pass unit tests. Checkout handler builds URLs using Config.DashboardURL.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T03:24:38.830498+00:00",
        "completed_at": "2026-02-06T03:31:29.496628+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Implement Stripe Webhook Handler",
        "actor": "AI",
        "description": "Create `internal/api/handlers/stripe_webhook.go`. Implement `Handle`. Logic: Verify signature using `StripeVerifier` (Phase 3). Switch on event type. Call `SubscriptionStateRepo` to update org plan/status. Ensure `invoice.paid` events trigger `ResumeAllByOrgID` (stub this call for now, implemented in Task 5.1).",
        "priority": "High",
        "relevant_files": [
          "05e-api-billing.md (Section 7, 9.2)"
        ],
        "relevant_flows": [
          "BILL-007"
        ],
        "definition_of_done": "Unit tests verify event routing and signature failure responses.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T03:31:44.294137+00:00",
        "completed_at": "2026-02-06T03:39:40.901803+00:00",
        "satisfaction_iterations": 2,
        "skip_reason": null
      },
      {
        "task": "Implement Organization, User & Audit Repositories",
        "actor": "AI",
        "description": "Create `internal/db/org_repo.go`, update `internal/db/user_repo.go`, and create `internal/db/audit_repo.go`. \n1. **Org**: Implement Create, Update, Delete.\n2. **User**: Add CountOwners, CreateInvited.\n3. **Audit**: Implement `Log` (write) and `List` (read with filters) for the `audit_log` table. This is required by `05d-api-organization.md` for the audit log endpoint.",
        "priority": "Critical",
        "relevant_files": [
          "05d-api-organization.md (Section 2.2, 3.4)",
          "02-foundation-db.md (Section 3.1, 5.3)"
        ],
        "relevant_flows": [
          "USER-001",
          "USER-003",
          "OBS-011"
        ],
        "definition_of_done": "Integration tests verify CRUD, constraints, and audit log filtering.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T03:39:56.003405+00:00",
        "completed_at": "2026-02-06T03:49:04.199431+00:00",
        "satisfaction_iterations": 2,
        "skip_reason": null
      },
      {
        "task": "Implement API Key Management",
        "actor": "AI",
        "description": "Create `internal/db/apikey_repo.go` and `internal/api/handlers/apikey.go`. \n1. **Repo**: List (with prefix filter), Create, Rotate, Revoke.\n2. **Handler**: `Create` must generate plaintext secret, Hash it, save Hash to DB, and return Plaintext in response **once**. `Rotate` implements dual-validity logic.",
        "priority": "Critical",
        "relevant_files": [
          "05d-api-organization.md (Section 5)",
          "02-foundation-db.md (Section 5.1)"
        ],
        "relevant_flows": [
          "USER-011",
          "USER-012"
        ],
        "definition_of_done": "Tests confirm plaintext secret is never stored. Rotation sets correct expiry.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T03:49:19.382327+00:00",
        "completed_at": "2026-02-06T04:00:42.486869+00:00",
        "satisfaction_iterations": 2,
        "skip_reason": null
      },
      {
        "task": "Implement Organization Handlers",
        "actor": "AI",
        "description": "Create `internal/api/handlers/organization.go` and `users.go`. Implement Org `Get/Update/Delete`, User `List/Invite/Remove`, and Audit `ListAuditLogs`. Inject `PlanRegistry`, `EmailService` (Phase 3 Mock), and `AuditRepository`. Mount routes in `main.go`. **Constraint**: Org Create must wrap DB inserts and Stripe Customer creation in a logic flow that handles partial failures (Best Effort Stripe).",
        "priority": "High",
        "relevant_files": [
          "05d-api-organization.md (Section 3, 4)"
        ],
        "relevant_flows": [
          "USER-001",
          "USER-004",
          "OBS-011"
        ],
        "definition_of_done": "Handlers pass unit tests. Invite flow calls EmailService mock.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T04:00:57.018063+00:00",
        "completed_at": "2026-02-06T04:16:11.483841+00:00",
        "satisfaction_iterations": 2,
        "skip_reason": null
      },
      {
        "task": "Implement Forecast Run Repository",
        "actor": "AI",
        "description": "Create `internal/db/forecast_repo.go`. Implement `ForecastRunRepository`. Methods: `GetLatestServing(model)` (must return last *completed* run), `Create`, `MarkComplete`, `MarkFailed`. Ensure `GetLatestServing` correctly orders by `run_timestamp DESC`.",
        "priority": "High",
        "relevant_files": [
          "05c-api-forecasts.md (Section 4.1)",
          "02-foundation-db.md (Section 6)"
        ],
        "relevant_flows": [
          "FQRY-001",
          "FCST-005"
        ],
        "definition_of_done": "Integration tests verify retrieval of latest COMPLETED run.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T04:16:26.869448+00:00",
        "completed_at": "2026-02-06T04:21:06.845068+00:00",
        "satisfaction_iterations": 2,
        "skip_reason": null
      },
      {
        "task": "Implement Zarr Reader Service",
        "actor": "AI",
        "description": "Create `internal/forecasts/reader.go`. Implement `ForecastReader` interface. Use `aws-sdk-go-v2` to fetch S3 ranges. Implement a minimal Zarr v2 chunk parser (Decompress Zstd -> Read Float32 bytes). **Constraint**: Do not implement full Zarr spec; only what is needed for `ReadPoint` (bilinear interp from chunk) and `ReadTile`.",
        "priority": "Critical",
        "relevant_files": [
          "05c-api-forecasts.md (Section 4.2)"
        ],
        "relevant_flows": [
          "FQRY-001"
        ],
        "definition_of_done": "Unit tests with a sample local .zarr file (in `test/data`) verify correct float value extraction.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T04:21:18.910973+00:00",
        "completed_at": "2026-02-06T04:29:56.536256+00:00",
        "satisfaction_iterations": 2,
        "skip_reason": null
      },
      {
        "task": "Implement Forecast Service & Handler",
        "actor": "AI",
        "description": "Create `internal/forecasts/service.go` and `internal/api/handlers/forecasts.go`. \n1. **Service**: `GetPointForecast` implements **Model Blending**: Check Nowcast availability -> Fallback to MediumRange. Check CONUS bounds.\n2. **Handler**: `HandleGetPoint`, `HandleGetBatch`. Parse inputs, call Service, return JSON.\n3. Mount routes in `main.go`.",
        "priority": "High",
        "relevant_files": [
          "05c-api-forecasts.md (Section 3, 5, 6)"
        ],
        "relevant_flows": [
          "FQRY-001",
          "FQRY-002"
        ],
        "definition_of_done": "Service unit tests verify fallback logic. Handler returns correct JSON structure.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T08:31:02.548360+00:00",
        "completed_at": "2026-02-06T08:36:25.764545+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Implement WatchPoint Repository",
        "actor": "AI",
        "description": "Create `internal/db/watchpoint_repo.go`. Implement `WatchPointRepository`.\nMethods: `Create`, `GetByID`, `Update`, `Delete`, `List` (with filters), `UpdateStatusBatch`. Implement `UpdateChannelConfig` using `jsonb_set` for safe secret rotation. Ensure `tile_id` logic is handled by DB generated column (read-only in Go struct).",
        "priority": "Critical",
        "relevant_files": [
          "05b-api-watchpoints.md (Section 3.1)",
          "02-foundation-db.md (Section 3.2, 9.2)"
        ],
        "relevant_flows": [
          "WPLC-001",
          "HOOK-001"
        ],
        "definition_of_done": "Integration tests verify JSONB handling, atomic updates, and list filters.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T08:36:40.382716+00:00",
        "completed_at": "2026-02-06T08:50:51.187879+00:00",
        "satisfaction_iterations": 2,
        "skip_reason": null
      },
      {
        "task": "Implement Notification Repository",
        "actor": "AI",
        "description": "Create `internal/db/notification_repo.go`. Implement `NotificationRepository`.\nMethods: `List` (with complex filtering), `Create` (notifications), `CancelDeferredDeliveries`. Logic: `List` must perform a JOIN with `notification_deliveries` to hydrate the `Channels` field in the result DTO. This supports the Notification History endpoint.",
        "priority": "High",
        "relevant_files": [
          "02-foundation-db.md (Section 4.2, 9.2)",
          "01-foundation-types.md (Section 10.6)"
        ],
        "relevant_flows": [
          "INFO-001",
          "INFO-002"
        ],
        "definition_of_done": "Integration tests verify the JOIN logic correctly populates delivery statuses.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T08:51:06.801006+00:00",
        "completed_at": "2026-02-06T08:58:51.429041+00:00",
        "satisfaction_iterations": 3,
        "skip_reason": null
      },
      {
        "task": "Implement Evaluation Trigger (SQS Producer)",
        "actor": "AI",
        "description": "Create `internal/queue/trigger.go`. Implement a concrete struct satisfying the `EvaluationTrigger` interface. Uses `aws-sdk-go-v2/service/sqs` to send `EvalMessage` payloads to the configured SQS queues. Logic must select between `Standard` and `Urgent` queues based on the ForecastType in the message (or default to Standard for targeted resume).",
        "priority": "High",
        "relevant_files": [
          "05b-api-watchpoints.md (Section 3.2)",
          "01-foundation-types.md (Section 10.7)"
        ],
        "relevant_flows": [
          "WPLC-006"
        ],
        "definition_of_done": "Unit tests using a Mock SQS Client verify correct Queue URL selection and JSON payload serialization.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T08:59:07.966150+00:00",
        "completed_at": "2026-02-06T09:03:29.803184+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Implement WatchPoint Core Handlers",
        "actor": "AI",
        "description": "Create `internal/api/handlers/watchpoints.go`. Implement `Create`, `Get`, `Update`, `Delete`, `Pause`, `Resume`, and `GetNotificationHistory`. \n1. Inject `UsageEnforcer` (Billing), `ForecastProvider` (Forecast Service), `NotificationRepository`, and `EvaluationTrigger` (SQS Producer).\n2. `Create`: Validate -> CheckLimit -> GetSnapshot -> Insert.\n3. `Resume`: Update Status -> Cancel Deferred -> Trigger Evaluation.\n4. Mount routes.",
        "priority": "Critical",
        "relevant_files": [
          "05b-api-watchpoints.md (Section 6.1 - 6.4, 6.11)"
        ],
        "relevant_flows": [
          "WPLC-001",
          "WPLC-006",
          "INFO-001"
        ],
        "definition_of_done": "Handler tests mock the dependencies and verify flow control.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T09:05:39.348546+00:00",
        "completed_at": "2026-02-06T09:14:19.147185+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Implement WatchPoint Bulk Handlers",
        "actor": "AI",
        "description": "Append to `internal/api/handlers/watchpoints.go`. Implement `BulkCreate` and `BulkTagUpdate`. \n1. **BulkCreate**: Use `errgroup` to run `Validator` in parallel (simulating async webhook checks). Call `Repo.CreateBatch`. Return partial success response.\n2. **BulkTagUpdate**: Call `Repo.UpdateTagsBatch` (atomic array ops).",
        "priority": "High",
        "relevant_files": [
          "05b-api-watchpoints.md (Section 6.5, 6.10)"
        ],
        "relevant_flows": [
          "WPLC-011",
          "BULK-005"
        ],
        "definition_of_done": "Tests verify error aggregation logic in BulkCreate.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T09:14:34.918131+00:00",
        "completed_at": "2026-02-06T09:22:49.768039+00:00",
        "satisfaction_iterations": 2,
        "skip_reason": null
      },
      {
        "task": "Final API Assembly & Integration Test",
        "actor": "AI",
        "description": "1. Review `cmd/api/main.go`. Ensure ALL stubs/mocks are replaced with the real Repositories and Services created in this phase. Ensure all routes are mounted.\n2. Create `test/api_integration_test.go` (outside internal). Write a test suite that boots the `Server` against the Docker DB. Execute a sequence: Signup -> Login -> Get Token -> Create WatchPoint -> Get WatchPoint. Verify status codes and database side-effects.",
        "priority": "Critical",
        "relevant_files": [
          "05a-api-core.md (Section 3.2)",
          "12-operations.md (Section 2.1)"
        ],
        "relevant_flows": [
          "INT-001"
        ],
        "definition_of_done": "`go test -v test/api_integration_test.go` passes against the running docker environment.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T09:23:07.857837+00:00",
        "completed_at": "2026-02-06T09:39:08.144573+00:00",
        "satisfaction_iterations": 2,
        "skip_reason": null
      }
    ],
    "status": "unprocessed",
    "phase_completed_at": null,
    "phase_verification": null
  },
  {
    "title": "Phase 6: Scientific Compute & Evaluation",
    "description": "Implement the asynchronous worker layer. First, build the `Batcher` (Go) from `06-batcher.md` to define the SQS message contract and tile grouping logic. Second, implement the `Eval Worker` (Python) from `07-eval-worker.md` and the `RunPod` inference logic from `11-runpod.md`. This handles the heavy lifting: Zarr I/O, condition evaluation, and notification queueing. Definition of Done: The Batcher can trigger from a local S3 event, and the Python worker can successfully process a message from LocalStack SQS and write state to Postgres.",
    "subItems": [
      {
        "task": "Implement Batcher Repository (Tile Counting)",
        "actor": "AI",
        "description": "Create `internal/db/batcher_repo.go`. Implement `GetActiveTileCounts`. This must execute the optimized Index-Only Scan query defined in `06-batcher.md`: `SELECT tile_id, COUNT(*) ... GROUP BY tile_id`. Do NOT use the deprecated `active_tiles` table strategy.",
        "priority": "Critical",
        "relevant_files": [
          "06-batcher.md (Section 5)",
          "02-foundation-db.md (Section 3.2)"
        ],
        "relevant_flows": [
          "EVAL-001"
        ],
        "definition_of_done": "Integration test `batcher_repo_test.go` seeds 1000 random WatchPoints and asserts the returned map matches the expected distribution.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T09:44:54.235745+00:00",
        "completed_at": "2026-02-06T09:49:27.111218+00:00",
        "satisfaction_iterations": 2,
        "skip_reason": null
      },
      {
        "task": "Implement Batcher Core Logic (Pagination & Routing)",
        "actor": "AI",
        "description": "Create `internal/batcher/logic.go`. Implement the pure function `generateMessages` which handles the Hot Tile Pagination logic (`MAX_PAGE_SIZE=500`). Implement `resolveQueue` to map ForecastType to Urgent/Standard queue URLs. Implement `processRun` which orchestrates the flow and performs the 'Phantom Run' check (`IMPL-003`) by querying `ForecastRunRepository` before processing.",
        "priority": "Critical",
        "relevant_files": [
          "06-batcher.md (Section 5)",
          "01-foundation-types.md (Section 10.6)"
        ],
        "relevant_flows": [
          "EVAL-002",
          "IMPL-003"
        ],
        "definition_of_done": "Unit tests verify that a tile with 1200 items generates 3 `EvalMessage` structs with correct Page indices.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T09:49:40.384363+00:00",
        "completed_at": "2026-02-06T09:55:28.112936+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Implement Batcher Handler & SQS Integration",
        "actor": "AI",
        "description": "Create `cmd/batcher/main.go`. Wire the `SQSClient` (using AWS SDK v2), `MetricPublisher` (CloudWatch), and the Repositories. Implement the `Handler` function to parse `s3Event`, validate the bucket name against Config, and call `processRun`. Ensure `ForecastReady` metric is emitted on success.",
        "priority": "High",
        "relevant_files": [
          "06-batcher.md (Section 6, 7)",
          "04-sam-template.md (Section 5.1)"
        ],
        "relevant_flows": [
          "OBS-001"
        ],
        "definition_of_done": "Handler compiles. Local test with a sample S3 event JSON successfully calls the Mock SQS client.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T09:55:41.108328+00:00",
        "completed_at": "2026-02-06T10:05:39.235821+00:00",
        "satisfaction_iterations": 2,
        "skip_reason": null
      },
      {
        "task": "Set up Python Environment for Workers",
        "actor": "AI",
        "description": "Create `worker/requirements.txt` containing `numpy`, `xarray`, `zarr`, `s3fs`, `psycopg[binary]`, `pydantic-settings`, `fastapi`, `uvicorn`, and `aws-lambda-powertools`. Update `Makefile` with a `lint-python` target (using `black` and `mypy`). Create a shared `worker/shared` module structure for code reuse between Eval and RunPod workers if possible, or strictly separate if deployment requires isolation (Plan: strictly separate `worker/eval` and `runpod/` to mimic production isolation, but use same requirements file for dev simplicity).",
        "priority": "High",
        "relevant_files": [
          "07-eval-worker.md (Section 7)",
          "11-runpod.md (Section 6)"
        ],
        "relevant_flows": [],
        "definition_of_done": "`pip install -r worker/requirements.txt` succeeds. Linting passes.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T10:05:51.241780+00:00",
        "completed_at": "2026-02-06T10:10:05.083636+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Implement RunPod Mock Engine & Zarr Writer",
        "actor": "AI",
        "description": "In `runpod/`, implement `zarr_writer.py` and `mock_engine.py`. The `MockEngine` must generate random `numpy` arrays matching the Atlas/StormScope dimensions (`lat=721`, `lon=1440`). The `ZarrWriter` must implement the **Write-Side Halo** logic (padding 1 pixel) as strictly defined in `11-runpod.md`. Use `zstd` compression level 3.",
        "priority": "Critical",
        "relevant_files": [
          "11-runpod.md (Section 3, 4)"
        ],
        "relevant_flows": [
          "FCST-001",
          "FCST-002"
        ],
        "definition_of_done": "Unit test writes a mock Zarr to a temporary directory. `xarray.open_zarr` confirms successful read and correct dimensions.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T10:10:16.982657+00:00",
        "completed_at": "2026-02-06T10:22:55.513177+00:00",
        "satisfaction_iterations": 3,
        "skip_reason": null
      },
      {
        "task": "Implement RunPod Local Simulator (FastAPI)",
        "actor": "AI",
        "description": "Create `runpod/sim.py`. This script uses FastAPI to expose a `POST /run` endpoint. It parses the `InferencePayload` (Section 2 of `11-runpod.md`), invokes the `InferenceHandler` (wrapping MockEngine + ZarrWriter), and returns the standard RunPod response JSON. Configure it to write to MinIO (via `s3fs` and env vars).",
        "priority": "High",
        "relevant_files": [
          "11-runpod.md (Section 2, 4.2)"
        ],
        "relevant_flows": [
          "FCST-003"
        ],
        "definition_of_done": "Running `python runpod/sim.py` starts a server. `curl` with a payload triggers Zarr creation in MinIO.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T10:23:08.381537+00:00",
        "completed_at": "2026-02-06T10:46:18.904266+00:00",
        "satisfaction_iterations": 3,
        "skip_reason": null
      },
      {
        "task": "Implement Eval Worker Domain Models",
        "actor": "AI",
        "description": "Create `worker/eval/models.py`. Define Pydantic models for `EvalMessage`, `NotificationEvent`, `WatchPoint`, `Condition`, `EvaluationState`, and `MonitorSummary`. **CRITICAL**: These must exactly match the JSON keys defined in `01-foundation-types.md` (snake_case) to ensure compatibility with the Go-generated SQS messages.",
        "priority": "Critical",
        "relevant_files": [
          "07-eval-worker.md (Section 3)",
          "01-foundation-types.md (Section 13)"
        ],
        "relevant_flows": [
          "EVAL-001"
        ],
        "definition_of_done": "`mypy` passes. Test script verifies JSON serialization matches expected schema.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T10:46:31.756631+00:00",
        "completed_at": "2026-02-06T10:53:55.110531+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Implement Forecast Reader (Zarr I/O)",
        "actor": "AI",
        "description": "Create `worker/eval/reader.py`. Implement `ForecastReader.load_tile`. Use `xarray` and `s3fs` to fetch the specific tile chunk defined by the `tile_id` in the message. Handle `FileNotFoundError` by raising `ForecastExpiredError`. Handle checksum failures by raising `ForecastCorruptError`. Ensure it reads from MinIO in local dev.",
        "priority": "High",
        "relevant_files": [
          "07-eval-worker.md (Section 4.1)"
        ],
        "relevant_flows": [
          "EVAL-001",
          "FAIL-008"
        ],
        "definition_of_done": "Integration test: Can read the Zarr file generated by the RunPod Simulator in Task 6.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T10:54:07.771739+00:00",
        "completed_at": "2026-02-06T11:04:21.463225+00:00",
        "satisfaction_iterations": 2,
        "skip_reason": null
      },
      {
        "task": "Implement Eval Worker Config & Repo",
        "actor": "AI",
        "description": "Create `worker/eval/settings.py` (pydantic-settings loading SSM params) and `worker/eval/repo.py`. The Repo must implement `fetch_watchpoints` (SQL), `fetch_states`. Implement `commit_batch` which performs a transaction: 1. Updates DB State (Conditional on `last_forecast_run`), 2. Inserts Notifications, 3. **Sends `NotificationEvent` messages to the Notification SQS Queue** (using `boto3`). Ensure channel config is snapshotted.",
        "priority": "Critical",
        "relevant_files": [
          "07-eval-worker.md (Section 4.2, 7)",
          "CONC-006",
          "EVAL-001"
        ],
        "relevant_flows": [
          "EVAL-001"
        ],
        "definition_of_done": "Integration test: Can read/write state to DB and publish a message to LocalStack SQS.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T11:04:33.038681+00:00",
        "completed_at": "2026-02-06T11:13:53.151351+00:00",
        "satisfaction_iterations": 2,
        "skip_reason": null
      },
      {
        "task": "Implement Core Evaluator Logic & Monitor Mode",
        "actor": "AI",
        "description": "Create `worker/eval/logic/evaluator.py`, `monitor.py`, and `dedup.py`. Implement `evaluate_batch`. Include: 1. `ConfigPolicy` check (`EVAL-004`). 2. Condition evaluation. 3. Monitor Mode time-series extraction (Timezone conversion, Active Hours). 4. Temporal Deduplication using `seen_threats`. 5. First Eval Baseline logic (`EVAL-005`).",
        "priority": "Critical",
        "relevant_files": [
          "07-eval-worker.md (Section 5)",
          "EVAL-003",
          "EVAL-004"
        ],
        "relevant_flows": [
          "EVAL-003"
        ],
        "definition_of_done": "Unit tests cover: Config mismatch reset, Monitor mode deduplication (overlapping windows), and 'First Eval' suppression.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T11:14:05.866530+00:00",
        "completed_at": "2026-02-06T11:25:59.838578+00:00",
        "satisfaction_iterations": 2,
        "skip_reason": null
      },
      {
        "task": "Implement Eval Worker Lambda Handler",
        "actor": "AI",
        "description": "Create `worker/eval/handler.py`. Implement the `handler(event, context)` entrypoint. Logic: 1. Parse SQS batch. 2. Group by Tile ID. 3. `process_tile` loop with `TimeoutGuard`. 4. Catch `ForecastCorruptError` (ACK) vs other errors (Raise/NACK). 5. Emit `EvaluationLag` metric.",
        "priority": "High",
        "relevant_files": [
          "07-eval-worker.md (Section 6)",
          "FAIL-011"
        ],
        "relevant_flows": [
          "EVAL-001"
        ],
        "definition_of_done": "Local simulation script can invoke the handler with a mock SQS event and verify database side effects.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T11:26:12.416556+00:00",
        "completed_at": "2026-02-06T11:33:04.446270+00:00",
        "satisfaction_iterations": 2,
        "skip_reason": null
      },
      {
        "task": "Run End-to-End Local Verification",
        "actor": "AI",
        "description": "Create `scripts/verify-phase6.sh`. Sequence:\n1. Start `runpod/sim.py` (background).\n2. Send POST to Sim to generate Zarr in MinIO.\n3. Insert a test WatchPoint into Postgres.\n4. Invoke `cmd/batcher` with a manual JSON S3 event pointing to that Zarr.\n5. Verify SQS message exists in LocalStack.\n6. Invoke `worker/eval/handler.py` with that SQS message.\n7. Assert `notifications` table has a record.",
        "priority": "Normal",
        "relevant_files": [],
        "relevant_flows": [
          "INT-002"
        ],
        "definition_of_done": "Script runs successfully and outputs 'Phase 6 Verified'.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T11:33:18.001120+00:00",
        "completed_at": "2026-02-06T11:40:37.557447+00:00",
        "satisfaction_iterations": 2,
        "skip_reason": null
      }
    ],
    "status": "unprocessed",
    "phase_completed_at": null,
    "phase_verification": null
  },
  {
    "title": "Phase 7: System Orchestration",
    "description": "Implement the `09-scheduled-jobs.md` module (`DataPoller` and `Archiver`). This phase connects the static components into a living system by implementing the 'heartbeat' logic: polling for new data, triggering digests, and managing maintenance tasks. It effectively wires the database, external clients, and worker queues together. Definition of Done: Manually invoking the DataPoller locally triggers the Mock RunPod client and creates a `forecast_run` record in the DB.",
    "subItems": [
      {
        "task": "Implement Scheduler Repositories",
        "actor": "AI",
        "description": "Create `internal/db/scheduler_repos.go`. Implement the following repositories defined in `02-foundation-db.md`:\n\n1. `JobLockRepository`: Implement `Acquire` using `INSERT ... ON CONFLICT DO UPDATE`.\n2. `JobHistoryRepository`: Implement `Start`/`Finish`.\n3. `CalibrationRepository`: Implement `GetAll` (returns map) for Nowcast, `UpdateCoefficients` (for auto-apply), and `CreateCandidate` (for unsafe manual review).\n4. `VerificationRepository`: Implement `Save` (bulk metrics) and `GetAggregatedMetrics`.",
        "priority": "Critical",
        "relevant_files": [
          "02-foundation-db.md (Section 6, 9)",
          "09-scheduled-jobs.md (Section 4)"
        ],
        "relevant_flows": [
          "FCST-003",
          "OBS-005",
          "OBS-006"
        ],
        "definition_of_done": "Integration tests verify lock atomicity, calibration candidate insertion, and metric persistence against the Docker DB.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T11:41:07.659618+00:00",
        "completed_at": "2026-02-06T11:46:50.971542+00:00",
        "satisfaction_iterations": 2,
        "skip_reason": null
      },
      {
        "task": "Implement RunPod Client",
        "actor": "AI",
        "description": "Create `internal/external/runpod.go`. Implement the `RunPodClient` interface using `BaseClient`. \n\n1. `TriggerInference`: Serialize `types.InferencePayload` (polymorphic JSON) and POST to RunPod. Return `id`.\n2. `CancelJob`: Implement job cancellation.\n\nEnsure payload struct tags match `11-runpod.md` contract.",
        "priority": "Critical",
        "relevant_files": [
          "09-scheduled-jobs.md (Section 5.1)",
          "11-runpod.md (Section 2)"
        ],
        "relevant_flows": [
          "FCST-003",
          "FCST-004"
        ],
        "definition_of_done": "Unit tests using `httptest` verify correct JSON serialization of the `InferencePayload`.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T11:47:04.850326+00:00",
        "completed_at": "2026-02-06T11:52:33.388991+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Implement Upstream S3 Source",
        "actor": "AI",
        "description": "Create `internal/forecasts/upstream.go`. Implement `UpstreamSource` interface using AWS SDK v2. Logic: `CheckAvailability` lists objects in target bucket (GFS/GOES/MRMS) matching timestamp format. \n\n**CRITICAL**: Use `AWS_ENDPOINT_URL` to target MinIO in local dev.",
        "priority": "High",
        "relevant_files": [
          "09-scheduled-jobs.md (Section 5.1)"
        ],
        "relevant_flows": [
          "FCST-003"
        ],
        "definition_of_done": "Unit test validates S3 key parsing logic.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T11:52:45.703355+00:00",
        "completed_at": "2026-02-06T11:58:51.461178+00:00",
        "satisfaction_iterations": 2,
        "skip_reason": null
      },
      {
        "task": "Create Upstream Data Seeder Script",
        "actor": "AI",
        "description": "Create `scripts/seed-upstream-data.sh`. This script is required for local testing of the Data Poller. It must:\n1. Create buckets `noaa-gfs-bdp-pds`, `noaa-goes16`, `noaa-mrms-pds` in the local MinIO instance.\n2. Upload dummy 0-byte files with valid naming conventions (e.g., `gfs.20231027/00/atmos/gfs.t00z.pgrb2.0p25.f000`).",
        "priority": "Normal",
        "relevant_files": [
          "12-operations.md (Section 2.1)"
        ],
        "relevant_flows": [],
        "definition_of_done": "Script runs against local MinIO and creates accessible objects.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T11:59:05.471444+00:00",
        "completed_at": "2026-02-06T12:18:45.307660+00:00",
        "satisfaction_iterations": 3,
        "skip_reason": null
      },
      {
        "task": "Implement Data Poller Service Logic",
        "actor": "AI",
        "description": "Create `internal/scheduler/poller.go`. Implement `Poll`. \n1. Query `ForecastRunRepo`.\n2. **Nowcast Sync**: Instantiate `GoesSource` and `MrmsSource`, find timestamp intersection (5m tolerance).\n3. If new data: Create `ForecastRun`, Fetch Calibration Map, Construct `InferencePayload`, Trigger RunPod, Update DB.\n4. Respect `Limit` parameter.",
        "priority": "Critical",
        "relevant_files": [
          "09-scheduled-jobs.md (Section 5.2)",
          "FAIL-005"
        ],
        "relevant_flows": [
          "FCST-003",
          "FAIL-005"
        ],
        "definition_of_done": "Unit tests cover Nowcast synchronization logic (intersection). Integration test runs full poll cycle.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T12:21:51.351331+00:00",
        "completed_at": "2026-02-06T12:30:35.667674+00:00",
        "satisfaction_iterations": 1,
        "skip_reason": null
      },
      {
        "task": "Implement Data Poller Handler",
        "actor": "AI",
        "description": "Create `cmd/data-poller/main.go`. Initialize sources and repos. Implement `Handler(ctx, input DataPollerInput)`. Check `ForceRetry`. Execute Poll logic. Wrap in `lambda.Start`.",
        "priority": "High",
        "relevant_files": [
          "09-scheduled-jobs.md (Section 5)"
        ],
        "relevant_flows": [
          "FCST-003"
        ],
        "definition_of_done": "Compiles. Can be invoked via `main.go`.",
        "status": "complete",
        "reports": [],
        "started_at": "2026-02-06T12:32:02.496259+00:00",
        "completed_at": "2026-02-06T12:36:36.837568+00:00",
        "satisfaction_iterations": 2,
        "skip_reason": null
      },
      {
        "task": "Implement Usage Aggregator",
        "actor": "AI",
        "description": "Create `internal/scheduler/usage.go`. Implement `SnapshotDailyUsage`.\n1. Query batch of Org IDs with stale `rate_limits`.\n2. **Iterative Locking**: For each ID, start Tx, `SELECT FOR UPDATE`, insert `usage_history`, check Overage (update `overage_started_at`), reset `rate_limits`, Commit.",
        "priority": "Critical",
        "relevant_files": [
          "09-scheduled-jobs.md (Section 7.2)"
        ],
        "relevant_flows": [
          "SCHED-001",
          "SCHED-002"
        ],
        "definition_of_done": "Integration tests verify race-free reset of rate limits.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement Digest Scheduler",
        "actor": "AI",
        "description": "Create `internal/scheduler/digest.go`. Implement `TriggerDigests`.\n1. Query `organizations` where `next_digest_at <= now`.\n2. Enqueue `monitor_digest` message to SQS.\n3. Calculate next run time (Timezone aware).\n4. Update `next_digest_at`.",
        "priority": "High",
        "relevant_files": [
          "09-scheduled-jobs.md (Section 7.1)"
        ],
        "relevant_flows": [
          "NOTIF-003"
        ],
        "definition_of_done": "Unit tests verify next-run calculation.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement Maintenance Services",
        "actor": "AI",
        "description": "Create `internal/scheduler/maintenance.go`. Implement:\n1. `CleanupService`: `PurgeSoftDeletedOrgs` (Cascade), `PurgeExpiredInvites`, `RequeueDeferredNotifications`, `PurgeIdempotencyKeys`.\n2. `ArchiverService`: `ArchiveExpired` (Event Mode WPs).\n3. `TierTransitionService`: `EnforceRetention` (Delete old S3 forecasts).\nUse fixed batch size strategy to avoid timeouts.",
        "priority": "High",
        "relevant_files": [
          "09-scheduled-jobs.md (Section 7.4, 7.6, 7.8, 7.9)",
          "MAINT-005"
        ],
        "relevant_flows": [
          "WPLC-009",
          "MAINT-001",
          "MAINT-005",
          "NOTIF-002"
        ],
        "definition_of_done": "Integration tests confirm database rows are deleted/updated and TierTransition calls Mock S3 delete.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement Forecast Operations Services",
        "actor": "AI",
        "description": "Create `internal/scheduler/forecast_ops.go`. Implement:\n1. `VerificationService`: Trigger RunPod (`TaskType=verification`).\n2. `CalibrationService`: Trigger RunPod (`TaskType=calibration`). **Safety Check**: Read proposed coefficients from S3/Payload (Mock for now). If delta > 15%, call `Repo.CreateCandidate` (Manual Review). Else, `Repo.UpdateCoefficients` (Auto-Apply).\n3. `ForecastReconciler`: Query stuck jobs, Call `RunPodClient.CancelJob`, Update DB status.",
        "priority": "High",
        "relevant_files": [
          "09-scheduled-jobs.md (Section 7.3, 7.4, 7.5)",
          "OBS-006"
        ],
        "relevant_flows": [
          "OBS-005",
          "OBS-006",
          "FCST-004"
        ],
        "definition_of_done": "Unit tests for Calibration Safety Check logic. Mock RunPod client verifies correct task types and cancellation.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement Billing & System Operations Services",
        "actor": "AI",
        "description": "Create `internal/scheduler/system_ops.go`. Implement:\n1. `StripeSyncer`: Repair null customer IDs + State Sync (Remote vs Local check).\n2. `SubscriptionEnforcer`: `EnforcePaymentFailure` (Pause for delinquency) and `EnforceOverage` (Pause LIFO using `WatchPointRepo.PauseExcessByOrgID`).\n3. `CanaryVerifier`: Query WatchPoints with `system_role: canary`. Compare `previous_trigger_state` against metadata expectation. Emit Metrics via `MetricsCollector`.",
        "priority": "High",
        "relevant_files": [
          "09-scheduled-jobs.md (Section 7.7, 7.10)",
          "OBS-008"
        ],
        "relevant_flows": [
          "SCHED-003",
          "BILL-006",
          "BILL-011",
          "OBS-008"
        ],
        "definition_of_done": "Enforcer logic verified via integration test: ensure LIFO pausing works.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement Archiver Handler (Multiplexer)",
        "actor": "AI",
        "description": "Create `cmd/archiver/main.go`. Define `TaskType` constants. Wire `ServiceRegistry` (eagerly loading all services from previous tasks). Handler logic:\n1. Parse payload.\n2. Acquire `JobLock`.\n3. Switch `TaskType` -> Call Service method.\n4. Log `JobHistory`.",
        "priority": "Critical",
        "relevant_files": [
          "09-scheduled-jobs.md (Section 6)"
        ],
        "relevant_flows": [
          "SCHED-001"
        ],
        "definition_of_done": "Handler compiles. Unit test verifies routing.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement Job Runner Tool",
        "actor": "AI",
        "description": "Create `cmd/tools/job-runner/main.go`. CLI tool to invoke schedulers. Usage: `go run ... --task=aggregate_usage`. Constructs JSON payload and invokes core logic (bypassing Lambda shim).",
        "priority": "High",
        "relevant_files": [],
        "relevant_flows": [],
        "definition_of_done": "Tool exists. `make run-job` target added.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Final Integration Verification Script",
        "actor": "AI",
        "description": "Create `scripts/verify-phase7.sh`. \n1. Run `seed-upstream-data.sh`.\n2. Use `job-runner` to trigger `poll_data` -> Verify `forecast_runs` created.\n3. Verify MinIO has new Zarr file (via RunPod Sim from Phase 6).\n4. Insert dummy `rate_limits`.\n5. Use `job-runner` to trigger `aggregate_usage` -> Verify `usage_history`.",
        "priority": "Normal",
        "relevant_files": [],
        "relevant_flows": [
          "FCST-003",
          "SCHED-002"
        ],
        "definition_of_done": "Script runs successfully and prints 'Phase 7 Verified'.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      }
    ],
    "status": "unprocessed",
    "phase_completed_at": null,
    "phase_verification": null
  },
  {
    "title": "Phase 8: Notification Workers",
    "description": "Implement the `email-worker` (`08b`) and `webhook-worker` (`08c`), underpinned by the shared `08a-notification-core` logic. This includes the template rendering engine, SSRF protection, and the retry/backoff state machine for delivery. Definition of Done: Enqueuing a message to the local `notification-queue` results in a logged email (Mock SendGrid) or a successful local HTTP POST (Webhook).",
    "subItems": [
      {
        "task": "Implement Security Transport (SSRF)",
        "actor": "AI",
        "description": "Create `internal/security/transport.go`. Implement `SafeTransport` struct wrapping `http.Transport`. Implement `CheckRedirect` function. Use the `SSRFValidator` (from `internal/types/validation.go`) to validate IPs during DNS resolution and redirects. Logic: Enforce 500ms timeout on DNS resolution, block private IPs/Localhost/CloudMetadata. This is required by the Webhook Worker.",
        "priority": "Critical",
        "relevant_files": [
          "08c-webhook-worker.md (Section 5.2)",
          "01-foundation-types.md (Section 5.2, 14.1)"
        ],
        "relevant_flows": [
          "API-002"
        ],
        "definition_of_done": "Unit tests confirm `SafeTransport` rejects localhost, private IPs, and redirects to private IPs.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Define Notification Messaging Types",
        "actor": "AI",
        "description": "Create or update `internal/types/messaging.go`. Define the `NotificationMessage` struct (the SQS envelope). Include fields: `NotificationID`, `WatchPointID`, `OrgID`, `EventType`, `Urgency`, `TestMode`, `Ordering` (metadata), `RetryCount`, `TraceID`, and `Payload` (map[string]any). This struct serves as the contract between Python Eval Worker and Go Notification Workers.",
        "priority": "Critical",
        "relevant_files": [
          "08a-notification-core.md (Section 3)"
        ],
        "relevant_flows": [
          "NOTIF-001"
        ],
        "definition_of_done": "Struct exists and tags match the Python Pydantic model expectations (snake_case).",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement Notification Core (Manager & Policy)",
        "actor": "AI",
        "description": "Create `internal/notification/core` package. \n1. Implement `DeliveryManager` using `NotificationRepository`. Logic: `EnsureDeliveryExists` (idempotent insert), `MarkSuccess`, `MarkFailure`, `MarkDeferred` (Quiet Hours), `CheckAggregateFailure`, `ResetNotificationState`.\n2. Implement `PolicyEngine`. Logic: Check `NotificationPreferences.QuietHours` against current time (converted to User Timezone). Return `PolicyResult` (Deliver/Defer/Suppress). Handle exceptions (Critical urgency).",
        "priority": "Critical",
        "relevant_files": [
          "08a-notification-core.md (Section 5.2, 6.1)",
          "02-foundation-db.md (Section 4.2)"
        ],
        "relevant_flows": [
          "NOTIF-002",
          "NOTIF-010"
        ],
        "definition_of_done": "Unit tests verify Quiet Hours logic correctly handles timezone conversion and exceptions. Integration tests verify DB state transitions.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement Digest Generator",
        "actor": "AI",
        "description": "Create `internal/notification/digest` package. Implement `DigestGenerator`. Logic: \n1. `Generate(current, previous)`: Deserializes `MonitorSummary` structs.\n2. Compares MaxValues and TriggeredPeriods.\n3. Checks `DigestConfig.SendEmpty`.\n4. Returns `DigestContent` struct suitable for template rendering.",
        "priority": "High",
        "relevant_files": [
          "08a-notification-core.md (Section 4.2, 6.2)",
          "01-foundation-types.md (Section 10.1)"
        ],
        "relevant_flows": [
          "NOTIF-003"
        ],
        "definition_of_done": "Unit tests verify diffing logic (detecting 'New Threat' vs 'Cleared').",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement Notification Publisher & Metrics",
        "actor": "AI",
        "description": "In `internal/notification/core`:\n1. Implement `NotificationPublisher` wrapping SQS client. Logic: `Publish(ctx, msg, delay)`. **Crucial**: Must increment `msg.RetryCount` before serializing to JSON.\n2. Implement `CloudWatchNotificationMetrics`. Wrap `MetricsCollector`. Implement `RecordDelivery(channel, result)`. Ensure dimensions match `OBS-010` spec.",
        "priority": "High",
        "relevant_files": [
          "08a-notification-core.md (Section 7.1, 5.3)"
        ],
        "relevant_flows": [
          "NOTIF-004",
          "OBS-010"
        ],
        "definition_of_done": "Unit test confirms `RetryCount` increments on publish.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement Email Worker Logic",
        "actor": "AI",
        "description": "Create `internal/notification/email`. \n1. Implement `TemplateEngine`. Load `EmailConfig.Templates` JSON at startup. Implement `Resolve` with fallback to \"default\". Implement `Prepare` (Timezone formatting).\n2. Implement `EmailChannel` satisfying `NotificationChannel`. Logic: `Deliver` calls `EmailProvider` (SendGrid Mock). Handle `ErrRecipientBlocked` as terminal failure.",
        "priority": "Critical",
        "relevant_files": [
          "08b-email-worker.md (Section 2, 3, 5)",
          "VERT-003"
        ],
        "relevant_flows": [
          "NOTIF-001",
          "VERT-003"
        ],
        "definition_of_done": "Integration test: Enqueue SQS message -> `EmailChannel` processes -> Mock Provider receives correct payload.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement Bounce Processor",
        "actor": "AI",
        "description": "In `internal/notification/email`, implement `BounceProcessor`. Logic: \n1. Parse `BounceEvent`.\n2. Update Delivery Status (`bounced`).\n3. Increment Channel Failure Count in `watchpoints` (Optimistic Lock).\n4. If count >= 3, Disable Channel.\n5. If disabled, look up Owner Email (via `UserRepo`) and send System Alert (via `EmailProvider`).",
        "priority": "High",
        "relevant_files": [
          "08b-email-worker.md (Section 6)",
          "USER-014"
        ],
        "relevant_flows": [
          "NOTIF-006",
          "USER-014"
        ],
        "definition_of_done": "Integration test simulates 3 bounces and verifies the channel is disabled in the DB.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement Webhook Logic (Platforms & Signing)",
        "actor": "AI",
        "description": "Create `internal/notification/webhook`.\n1. Implement `SignatureManager` (HMAC-SHA256). Logic: Generate `t=...,v1=...`. Support `v1_old` if rotation active.\n2. Implement `PlatformRegistry`. Logic: `Detect(url)` (Regex + Config Override). Implement formatters for `Slack` (Block Kit), `Teams` (Adaptive Cards), `Discord`, `Generic`.",
        "priority": "Critical",
        "relevant_files": [
          "08c-webhook-worker.md (Section 3, 4, 5.1)",
          "SEC-006"
        ],
        "relevant_flows": [
          "NOTIF-007",
          "HOOK-001"
        ],
        "definition_of_done": "Unit tests verify correct JSON output for Slack/Teams and correct HMAC signature generation.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement Webhook Channel & Rate Limits",
        "actor": "AI",
        "description": "In `internal/notification/webhook`: Implement `WebhookChannel`. Logic: \n1. Use `SafeTransport` HTTP client.\n2. `Deliver`: Sign payload, POST.\n3. Handle 429: Parse `Retry-After`. Return `Retryable=true` with specific delay.\n4. Handle 410 (Gone): Return `Terminal=true`.\n5. Handle Long Delay (>15m): Return specific error to trigger 'Parking' logic in Handler.",
        "priority": "Critical",
        "relevant_files": [
          "08c-webhook-worker.md (Section 2, 6)",
          "NOTIF-005"
        ],
        "relevant_flows": [
          "NOTIF-004",
          "NOTIF-005"
        ],
        "definition_of_done": "Integration test against a mock HTTP server returning 429 verifies correct retry delay calculation.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement Worker Entrypoints (Cmd)",
        "actor": "AI",
        "description": "Create `cmd/email-worker/main.go` and `cmd/webhook-worker/main.go`. \n1. Load Config.\n2. Initialize DB, Repos, Metrics, SQS Client.\n3. Initialize Channel (`EmailChannel` or `WebhookChannel`).\n4. Implement SQS Handler Loop: `Receive` -> `EnsureDeliveryExists` -> `channel.Deliver`.\n5. Handle Results: `Success` (Update DB), `Retry` (Publish new SQS msg with delay + Update DB), `Defer` (Update DB), `Fail` (Update DB).\n6. Wrap in `lambda.Start`.",
        "priority": "Critical",
        "relevant_files": [
          "08b-email-worker.md (Section 2)",
          "08a-notification-core.md (Section 7.1)"
        ],
        "relevant_flows": [
          "NOTIF-001"
        ],
        "definition_of_done": "Both binaries compile. ",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Verify Notification Flow Locally",
        "actor": "AI",
        "description": "Create `scripts/verify-phase8.sh`.\n1. Insert a Test WatchPoint and Notification into local DB.\n2. Manually enqueue a `NotificationMessage` to LocalStack `notification-queue`.\n3. Run `cmd/email-worker` (or webhook-worker) locally against LocalStack.\n4. Verify `notification_deliveries` table updated to `sent`.\n5. Verify Mock Provider (or stdout) shows delivery.",
        "priority": "Normal",
        "relevant_files": [],
        "relevant_flows": [
          "INT-002"
        ],
        "definition_of_done": "Script runs successfully and outputs 'Phase 8 Verified'.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      }
    ],
    "status": "unprocessed",
    "phase_completed_at": null,
    "phase_verification": null
  },
  {
    "title": "Phase 9: Local Integration Verification",
    "description": "Run the critical End-to-End (`INT-*`) flows against the fully assembled local stack. This involves seeding dummy Zarr data into MinIO, manually triggering the Batcher, and verifying that a WatchPoint moves from 'Active' to 'Triggered' and a Notification is dispatched. This is the final verification of logic before cloud resources are involved. Definition of Done: The 'Happy Path' (Create WP -> Simulate Forecast -> Receive Alert) passes locally.",
    "subItems": [
      {
        "task": "Enhance Forecast Seeder for Deterministic Scenarios",
        "actor": "AI",
        "description": "Modify `scripts/generate_sample_forecast.py` (created in Phase 6) to support a 'Scenario Mode'. Instead of random data, accept a JSON configuration file (e.g., `--scenario config.json`) that specifies exact float values for variables at specific Lat/Lon coordinates (Tile IDs). Logic: 1. Parse config. 2. Initialize Zarr array with zeros (or a safe baseline). 3. Apply the specific values to the array indices corresponding to the target coordinates. This is required to guarantee that `INT-001` triggers a threshold violation (e.g., Precip=80mm).",
        "priority": "Critical",
        "relevant_files": [
          "12-operations.md (Section 2.3)",
          "flow-simulations.md (INT-001)"
        ],
        "relevant_flows": [
          "INT-001"
        ],
        "definition_of_done": "Script runs with a config file. Inspecting the generated Zarr in MinIO (via python shell) confirms the specific value exists at the target index.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement Python Worker Local Harness",
        "actor": "AI",
        "description": "Create `worker/eval/dev_runner.py`. Since the Eval Worker is designed as a Lambda handler, it cannot run standalone. This script must: 1. Initialize the `EvalWorker` class. 2. Connect to LocalStack SQS (`sqs_eval_urgent` and `sqs_eval_standard`). 3. Enter a `while True` loop to poll for messages (`ReceiveMessage`). 4. Wrap received messages in a mock Lambda Event structure (`{'Records': [...]}`). 5. Invoke `handler.handler(event, context)`. 6. Handle ACKs/NACKs based on handler return/exception. This simulates the AWS Lambda runtime locally.",
        "priority": "Critical",
        "relevant_files": [
          "07-eval-worker.md (Section 6, 7)"
        ],
        "relevant_flows": [
          "EVAL-001"
        ],
        "definition_of_done": "Running `python worker/eval/dev_runner.py` connects to LocalStack and processes a manually enqueued SQS message.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Update Go Binaries for Local Execution (Stdin Support)",
        "actor": "AI",
        "description": "Update `cmd/batcher/main.go`, `cmd/email-worker/main.go`, and `cmd/webhook-worker/main.go`. Add logic to check `APP_ENV=local`. If true, the `main()` function should not call `lambda.Start()`. Instead, it should start a blocking loop (for workers: polling SQS; for batcher: reading JSON event from Stdin). This is critical to run these binaries on the host machine without the AWS Lambda Runtime Interface Emulator (RIE).",
        "priority": "Critical",
        "relevant_files": [
          "06-batcher.md (Section 6)",
          "08b-email-worker.md (Section 2)"
        ],
        "relevant_flows": [
          "INT-001"
        ],
        "definition_of_done": "`echo '{\"event\":...}' | go run cmd/batcher/main.go` runs successfully without panicking on missing Lambda RPC.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Create Local Service Orchestrator",
        "actor": "AI",
        "description": "Create a `scripts/start-local-stack.sh` script (or `Makefile` target `run-stack`). This script must: 1. Check if Docker services are up. 2. Start the Go binaries (`cmd/api`, `cmd/email-worker`) and the Python Harness (`worker/eval/dev_runner.py`) as background processes. **Note**: Do not start `batcher` as a daemon; it will be invoked on-demand by tests. 3. Redirect **stdout/stderr** of all processes to a unified log file `test_artifacts/system.log` (prefixed by service name). 4. Trap `SIGINT` to kill all background PIDs on exit.",
        "priority": "High",
        "relevant_files": [
          "12-operations.md (Section 2)"
        ],
        "relevant_flows": [
          "INT-002"
        ],
        "definition_of_done": "Running the script starts the API and Workers. The `test_artifacts/system.log` file populates with startup logs.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Scaffold E2E Test Suite",
        "actor": "AI",
        "description": "Create `test/e2e/e2e_test.go` and `test/e2e/helpers.go`. Setup a Go test suite using `testing` package. Implement helpers: `CreateUserAndOrg` (executes HTTP Signup), `CreateWatchPoint` (HTTP POST), `TriggerForecast` (executes Seeder script + calls `cmd/batcher` via `exec.Command` piping the S3 event JSON), and `WaitForNotification` (polls DB `notifications` table). Configure the suite to load `APP_ENV=local`.",
        "priority": "Critical",
        "relevant_files": [
          "flow-simulations.md (INT-001)"
        ],
        "relevant_flows": [
          "INT-001"
        ],
        "definition_of_done": "`go test ./test/e2e` compiles and runs a dummy test.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement INT-001 Test Case (Happy Path)",
        "actor": "AI",
        "description": "Add `TestHappyPath_EventMode` to the E2E suite. Logic: 1. Signup a new user via API. 2. Create an **Event Mode** WatchPoint with condition `precip_prob > 50%` at Lat/Lon 40.0/-74.0. 3. Call the Seeder to generate Zarr data with `precip_prob = 80%` at that location. 4. Trigger Forecast (runs Batcher). 5. Poll `notification_deliveries` table for `status='sent'`. 6. Assert that the delivery record exists and matches the WatchPoint ID.",
        "priority": "Critical",
        "relevant_files": [
          "flow-simulations.md (INT-001)",
          "05b-api-watchpoints.md (Section 6.1)"
        ],
        "relevant_flows": [
          "INT-001"
        ],
        "definition_of_done": "Test passes. Database shows a completed notification delivery.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement INT-002 Test Case (Traceability)",
        "actor": "AI",
        "description": "Add `TestTracePropagation` to the E2E suite. Logic: 1. Trigger the Happy Path flow. 2. Wait for completion. 3. Open `test_artifacts/system.log`. 4. Find the `Batcher` log entry containing `TraceID`. 5. Regex match to ensure the **SAME** TraceID appears in the `[EVAL-WORKER]` log line and the `[EMAIL-WORKER]` log line. Fail if IDs are missing or mismatched.",
        "priority": "High",
        "relevant_files": [
          "flow-simulations.md (INT-002)",
          "01-foundation-types.md (Section 10.7)"
        ],
        "relevant_flows": [
          "INT-002"
        ],
        "definition_of_done": "Test passes. Logs confirm TraceID propagation across process boundaries.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement INT-004 Test Case (Monitor Digest)",
        "actor": "AI",
        "description": "Add `TestMonitorMode_Digest` to the E2E suite. Logic must handle `EVAL-005` (First Eval Suppression): \n1. Create a **Monitor Mode** WatchPoint.\n2. **Phase 1 (Baseline)**: Seed \"Safe\" data (Precip=0). Trigger Batcher. Wait for Eval (verify `last_forecast_summary` populated in DB, but NO notification).\n3. **Phase 2 (Change)**: Seed \"Threat\" data (Precip=80). Trigger Batcher. Wait for Eval (verify `last_forecast_summary` updated).\n4. **Phase 3 (Digest)**: Execute `go run cmd/tools/job-runner --task=trigger_digests`.\n5. Poll `notification_deliveries` for a `monitor_digest` event type.",
        "priority": "High",
        "relevant_files": [
          "flow-simulations.md (INT-004)",
          "09-scheduled-jobs.md (Section 7.1)",
          "07-eval-worker.md (Section 5.2 - First Eval Rule)"
        ],
        "relevant_flows": [
          "INT-004",
          "NOTIF-003",
          "EVAL-005"
        ],
        "definition_of_done": "Test passes. Database shows a digest notification was created only after the cycle completed.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      }
    ],
    "status": "unprocessed",
    "phase_completed_at": null,
    "phase_verification": null
  },
  {
    "title": "Phase 10: Artifact Packaging",
    "description": "Transition from local binaries to cloud artifacts. Create `Dockerfile`s for the Python components (Eval Worker, RunPod Inference). Build these images and push them to AWS ECR (Elastic Container Registry). Update the SAM template references to point to these immutable image URIs. Definition of Done: Docker images are successfully built and exist in the AWS ECR repositories.",
    "subItems": [
      {
        "task": "Configure Docker Build Context",
        "actor": "AI",
        "description": "Create a `.dockerignore` file in the project root to optimize build context size. Explicitly exclude heavy local artifacts: `.git`, `.aws-sam`, `bin/`, `postgres_data/`, `minio_data/`, `localstack_data/`, and any local `.env` files. This ensures that `docker build .` remains fast and secure by not leaking local secrets or huge binary artifacts into the build daemon.",
        "priority": "High",
        "relevant_files": [
          "12-operations.md (Section 2.2)"
        ],
        "relevant_flows": [],
        "definition_of_done": "`.dockerignore` exists. Running `docker build . -f /dev/null` is instantaneous.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Create Eval Worker Dockerfile (Lambda/ARM64)",
        "actor": "AI",
        "description": "Create `worker/eval/Dockerfile`. \n\n**Architecture Requirement**: This image MUST target `linux/arm64` to match the `Architectures: arm64` setting in `04-sam-template.md`.\n\n**Base Image**: `public.ecr.aws/lambda/python:3.11`.\n\n**Steps**:\n1. Copy `worker/requirements.txt`.\n2. Run `pip install`.\n3. Copy the full `worker/` directory structure to `${LAMBDA_TASK_ROOT}/worker/`. This ensures imports like `from worker.eval import ...` function correctly.\n4. **Contract Verification**: Add a build stage `RUN python -m pytest worker/tests` to verify the Pydantic models against the schema logic implemented in Phase 6. Fail the build if tests fail.\n5. Set `CMD` to `worker.eval.handler.handler`.",
        "priority": "Critical",
        "relevant_files": [
          "07-eval-worker.md (Section 6, 7)",
          "04-sam-template.md (Section 1)"
        ],
        "relevant_flows": [
          "EVAL-001"
        ],
        "definition_of_done": "`docker build --platform linux/arm64 -f worker/eval/Dockerfile .` completes successfully. Pydantic model verification tests run during build.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Create RunPod Inference Dockerfile (GPU/x86)",
        "actor": "AI",
        "description": "Create `runpod/Dockerfile`. \n\n**Architecture Requirement**: This image MUST target `linux/amd64` to run on standard NVIDIA GPU instances.\n\n**Base Image**: `nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04`.\n\n**Steps**:\n1. Install system deps: `python3.11`, `python3-pip`, `git`.\n2. Copy `worker/requirements.txt` (shared deps) and run `pip install`.\n3. Copy `runpod/` directory to `/app`.\n4. Set `WORKDIR /app`.\n5. Set `CMD [ \"python3\", \"-u\", \"handler.py\" ]` (Matches `11-runpod.md` Section 6.1).\n\nNote: Do *not* copy model weights; rely on the Persistent Volume mount at `/runpod-volume/`.",
        "priority": "Critical",
        "relevant_files": [
          "11-runpod.md (Section 6.1)"
        ],
        "relevant_flows": [
          "FCST-001"
        ],
        "definition_of_done": "`docker build --platform linux/amd64 -f runpod/Dockerfile .` completes successfully.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement Build Automation with Cross-Compilation",
        "actor": "AI",
        "description": "Update `Makefile` with a `build-images` target. This target should:\n1. Get the current git commit hash: `SHA=$(git rev-parse --short HEAD)`.\n2. Build Eval Worker (Enforce ARM64): `docker build --platform linux/arm64 -t watchpoint/eval:$SHA -f worker/eval/Dockerfile .`\n3. Build RunPod Worker (Enforce AMD64): `docker build --platform linux/amd64 -t watchpoint/runpod:$SHA -f runpod/Dockerfile .`\n4. Tag both as `:latest` as well.",
        "priority": "Normal",
        "relevant_files": [
          "12-operations.md (Section 3)"
        ],
        "relevant_flows": [],
        "definition_of_done": "Running `make build-images` results in correct architecture images (inspect via `docker inspect`).",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Create Publish Script",
        "actor": "AI",
        "description": "Create `scripts/publish-images.sh`. This script handles the single-repo constraints defined in `04-sam-template.md`.\n\n**Logic**:\n1. Accept `ECR_URI` as an environment variable or argument (e.g., `123.dkr.ecr.us-east-1.amazonaws.com/watchpoint-eval-repo`).\n2. Check AWS Identity (`aws sts get-caller-identity`).\n3. Login to ECR (`aws ecr get-login-password`).\n4. **Eval Tagging**: Retag `watchpoint/eval:latest` -> `$ECR_URI:eval-latest`.\n5. **RunPod Tagging**: Retag `watchpoint/runpod:latest` -> `$ECR_URI:runpod-latest`.\n6. Push both tags to the *same* ECR repository.\n\nNote: The script should fail gracefully if `ECR_URI` is not reachable (since infrastructure isn't provisioned yet).",
        "priority": "High",
        "relevant_files": [
          "13-human-setup.md (Section 6.1)",
          "04-sam-template.md (Section 3.4)"
        ],
        "relevant_flows": [],
        "definition_of_done": "Script exists and is executable. Dry-run confirms that both images are targeted at the same repository URI with distinct tags.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      }
    ],
    "status": "unprocessed",
    "phase_completed_at": null,
    "phase_verification": null
  },
  {
    "title": "Phase 11: Human Setup & Bootstrap",
    "description": "Execute the protocol defined in `13-human-setup.md`. A human operator creates the necessary external accounts (Stripe, SendGrid, RunPod) and populates the AWS SSM Parameter Store with the required secrets. This provides the configuration 'Vault' that the cloud deployment will read. Definition of Done: All SSM parameters defined in `03-config.md` exist in the target AWS account.",
    "subItems": [
      {
        "task": "Scaffold Bootstrap CLI Tool",
        "actor": "AI",
        "description": "Create `cmd/ops/bootstrap/main.go`. Initialize a CLI application (using `flag` or `cobra`) that accepts `--env` (dev/staging/prod), `--profile` (AWS profile), and `--region` arguments. Configure the AWS SDK v2 Session. Implement a startup check that verifies the active AWS identity matches the intended environment/account to prevent cross-account accidents. Print a warning banner if `env=prod` and require an explicit interactive confirmation (typing 'yes').",
        "priority": "Critical",
        "relevant_files": [
          "13-human-setup.md (Section 1, 2)",
          "12-operations.md (Section 3.1)"
        ],
        "relevant_flows": [],
        "definition_of_done": "`go run cmd/ops/bootstrap/main.go --env=dev` prints the account ID and connects to AWS successfully. `prod` flag triggers confirmation prompt.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement SSM Manager",
        "actor": "AI",
        "description": "Create `cmd/ops/bootstrap/ssm.go`. Implement functions to interact with AWS Systems Manager Parameter Store:\n1. `ParameterExists(path string) bool`: Checks if a key is already set.\n2. `PutSecret(path string, value string, overwrite bool)`: Writes a `SecureString` parameter. \n3. `PutString(path string, value string)`: Writes a standard `String` parameter (for non-sensitive configs like RunPod Endpoint ID placeholders).",
        "priority": "Critical",
        "relevant_files": [
          "03-config.md (Section 4.1)",
          "13-human-setup.md (Section 4)"
        ],
        "relevant_flows": [],
        "definition_of_done": "Unit tests (or integration tests against LocalStack) verify parameters are written correctly with encryption.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement Input Validators (Active Probing)",
        "actor": "AI",
        "description": "Create `cmd/ops/bootstrap/validate.go`. Implement validators for the secrets defined in Doc 13:\n1. `ValidateDatabaseURL(url)`: Use `pgx` to attempt a connection. **Fail** if port is not `6543` (Supabase Transaction Mode).\n2. `ValidateStripeKey(key)`: Make a lightweight GET to `https://api.stripe.com/v1/account`.\n3. `ValidateSendGridKey(key)`: Make a GET to `https://api.sendgrid.com/v3/user/credits`.\n4. `ValidateRunPodKey(key)`: Regex/Length check only (API requires specific scopes).\n5. `ValidateRegex(input, pattern)`: Generic fallback for OAuth IDs.",
        "priority": "Critical",
        "relevant_files": [
          "13-human-setup.md (Section 3)",
          "10-external-integrations.md"
        ],
        "relevant_flows": [],
        "definition_of_done": "Validators correctly identify valid/invalid credentials in test cases.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement Internal Key Generator",
        "actor": "AI",
        "description": "Create `cmd/ops/bootstrap/generate.go`. Implement `GenerateSecureToken()` using `crypto/rand` to produce 32-byte hex-encoded strings. This will be used to automatically populate `SESSION_KEY` and `ADMIN_API_KEY` without user input, adhering to the security requirement of not displaying high-privilege internal secrets to the operator's console.",
        "priority": "High",
        "relevant_files": [
          "13-human-setup.md (Section 4 Table)",
          "03-config.md (Section 2.2)"
        ],
        "relevant_flows": [
          "SEC-001"
        ],
        "definition_of_done": "Generator produces consistent high-entropy strings.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement Main Bootstrap Logic Loop",
        "actor": "AI",
        "description": "Update `cmd/ops/bootstrap/main.go` to orchestrate the flow:\n1. Define the `SecretInventory` map (Human Label -> SSM Path -> Validator).\n2. Iterate through the inventory in the order defined in Doc 13.\n3. For each secret: Check existence in SSM. If missing, Prompt User (masking input). Run Validator. If Valid, Push to SSM. If Invalid, Retry Prompt.\n4. Handle `RunPodEndpointId` specifically: Check existence, if missing, write literal `pending_setup` to SSM.\n5. Auto-generate and push `SESSION_KEY` and `ADMIN_API_KEY` silently.",
        "priority": "Critical",
        "relevant_files": [
          "13-human-setup.md (Section 4, 6.3)"
        ],
        "relevant_flows": [],
        "definition_of_done": "The tool successfully walks through the full checklist, validates inputs, and populates SSM. It handles the `[Skip]` option for existing keys.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement Local Dev Export Flag",
        "actor": "AI",
        "description": "Add `--export-env` flag to the CLI. If set, after successfully validating/retrieving secrets, append them to a `.env` file in the project root. Map the SSM keys to the environment variables defined in `03-config.md` (e.g., `STRIPE_SECRET_KEY`). This bridges the gap between the Setup phase and Phase 9 (Local Verification).",
        "priority": "High",
        "relevant_files": [
          "03-config.md (Section 6.1)"
        ],
        "relevant_flows": [],
        "definition_of_done": "Running with `--export-env` produces a valid `.env` file usable by `docker-compose`.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Execute Bootstrap Protocol (The Setup)",
        "actor": "HUMAN",
        "description": "Run the `cmd/ops/bootstrap` tool targeting the `dev` environment (and subsequently `prod`). Follow the interactive prompts to:\n1. Create Supabase Project & Get Connection String.\n2. Get Stripe Keys (Test Mode for Dev).\n3. Get SendGrid Key & Verify Sender.\n4. Get RunPod API Key.\n5. Register OAuth Apps (Google/GitHub).\n6. The tool will auto-generate internal keys and populate AWS SSM.",
        "priority": "Critical",
        "relevant_files": [
          "13-human-setup.md (Section 3)"
        ],
        "relevant_flows": [
          "BILL-001",
          "NOTIF-001",
          "DASH-002"
        ],
        "definition_of_done": "The tool completes successfully. All parameters are visible in the AWS Systems Manager Console.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      }
    ],
    "status": "unprocessed",
    "phase_completed_at": null,
    "phase_verification": null
  },
  {
    "title": "Phase 12: Cloud Infrastructure Provisioning",
    "description": "Deploy the infrastructure defined in `04-sam-template.md` using the AWS SAM CLI. This provisions the API Gateway, Lambda functions, SQS queues, S3 buckets, and EventBridge rules in the target AWS environment. Definition of Done: The CloudFormation stack reaches `CREATE_COMPLETE` status, and the `/health` endpoint of the public API URL returns 200 OK.",
    "subItems": [
      {
        "task": "Implement Pre-flight Domain Validation Script",
        "actor": "AI",
        "description": "Create `scripts/preflight-check.sh`. This script checks if the `DOMAIN_NAME` environment variable is set. If set, it uses `aws acm list-certificates --region us-east-1` to verify a valid SSL certificate exists for that domain (required for CloudFront/Edge API mappings). If the certificate is missing or not 'ISSUED', the script must exit with a non-zero code to prevent a failing deployment. If `DOMAIN_NAME` is unset (Dev/Staging), it should log a warning but exit 0.",
        "priority": "High",
        "relevant_files": [
          "04-sam-template.md (Section 2.2, 3.1)",
          "12-operations.md (Section 3)"
        ],
        "relevant_flows": [],
        "definition_of_done": "Script exists and correctly identifies valid/invalid/missing ACM certificates based on the input domain.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement Artifact Bucket Provisioner",
        "actor": "AI",
        "description": "Create `scripts/provision-artifact-bucket.sh`. This script must idempotently create an S3 bucket named `watchpoint-artifacts-{account_id}-{region}` using the AWS CLI. It must apply a Lifecycle Configuration to expire objects (Lambda zip artifacts) after 30 days to prevent cost accumulation. The script should output the bucket name to stdout for use by the config generator.",
        "priority": "High",
        "relevant_files": [
          "12-operations.md (Section 3)"
        ],
        "relevant_flows": [],
        "definition_of_done": "Script creates (or verifies) the bucket and applies the lifecycle policy successfully.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement Model Weight Upload Script",
        "actor": "AI",
        "description": "Create `scripts/upload-weights.sh`. This script bridges the gap between local model files and the cloud environment. \n\nLogic:\n1. Accept arguments `--bucket`, `--atlas`, `--nowcast`, and optional `--mock`.\n2. If `--mock` is set, generate large dummy files (100MB) using `dd` to simulate model weights.\n3. Upload the files to `s3://{bucket}/weights/atlas.pt` and `s3://{bucket}/weights/stormscope.pt`.\n4. Ensure the bucket provided matches the Artifact Bucket created in the previous task.\n\nThis script is required for the Human Setup phase.",
        "priority": "High",
        "relevant_files": [
          "13-human-setup.md (Phase 4)",
          "11-runpod.md (Section 6.2)"
        ],
        "relevant_flows": [],
        "definition_of_done": "Script exists. Running with `--mock` successfully populates the target S3 bucket with dummy weight files.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement ECR Bootstrap Script",
        "actor": "AI",
        "description": "Create `scripts/bootstrap-ecr.sh`. This script resolves the Chicken-and-Egg dependency for container deployments. It must check if the ECR repository defined in `04-sam-template.md` (e.g., `watchpoint/eval-worker`) exists. If not, create it via `aws ecr create-repository`. It should output the Repository URI (e.g., `123.dkr.ecr...`). This ensures `sam build` has a valid target for container images.",
        "priority": "Critical",
        "relevant_files": [
          "04-sam-template.md (Section 3.4)",
          "12-operations.md (Section 3)"
        ],
        "relevant_flows": [],
        "definition_of_done": "Script runs idempotently and outputs the valid ECR Repository URI.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement SAM Config Generator",
        "actor": "AI",
        "description": "Create `scripts/generate-sam-config.sh`. This script generates `samconfig.toml` dynamically. \n1. Retrieve the Artifact Bucket name (from Task 2) and ECR URI (from Task 3).\n2. Define environments `[dev.deploy.parameters]`, `[staging...]`, `[prod...]`.\n3. Map `s3_bucket`, `stack_name` (e.g., `watchpoint-dev`), and `region` (`us-east-1`).\n4. **CRITICAL**: Inject `image_repositories = [\"EvalWorkerUrgent=$ECR_URI\", \"EvalWorkerStandard=$ECR_URI\"]` to bind the Lambda functions to the container repo.\n5. Map `parameter_overrides` to inject `AlertEmail=\"$ALERT_EMAIL\"` and `RunPodEndpointId=\"pending_setup\"`.",
        "priority": "Critical",
        "relevant_files": [
          "04-sam-template.md (Section 2.1)",
          "12-operations.md (Section 3.2)"
        ],
        "relevant_flows": [],
        "definition_of_done": "`samconfig.toml` is generated with correct bucket, parameter overrides, and image repository mappings.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement Deployment Make Target",
        "actor": "AI",
        "description": "Update `Makefile` with a `deploy-cloud` target. This target chains the scripts:\n1. `scripts/preflight-check.sh`\n2. `scripts/provision-artifact-bucket.sh`\n3. `scripts/bootstrap-ecr.sh`\n4. `scripts/generate-sam-config.sh`\n5. Executes `sam build` (compiles Go, builds Docker containers).\n6. Executes `sam deploy --config-env $(ENV)`.",
        "priority": "Critical",
        "relevant_files": [
          "12-operations.md (Section 3)",
          "04-sam-template.md (Section 1)"
        ],
        "relevant_flows": [],
        "definition_of_done": "`make deploy-cloud ENV=dev` successfully builds and initiates the CloudFormation stack deployment without interactive prompts.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement Stack Output Exporter",
        "actor": "AI",
        "description": "Create `scripts/export-stack-outputs.sh`. Run this post-deployment. Use `aws cloudformation describe-stacks` to fetch Outputs (ApiEndpoint, RunPodUserArn, etc.). Write these to `stack-outputs.json` (for tools) and `.env.cloud` (for shell sourcing).",
        "priority": "High",
        "relevant_files": [
          "04-sam-template.md (Section 8)"
        ],
        "relevant_flows": [],
        "definition_of_done": "Script generates files containing correct API URL and ARNs from the deployed stack.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement Remote Database Migration Target",
        "actor": "AI",
        "description": "Add `migrate-cloud` target to `Makefile`. \n1. Fetch `DATABASE_URL` from SSM using `aws ssm get-parameter` (decrypting SecureString).\n2. Run the `migrate` docker container (same as Phase 2) but targeting the retrieved Remote URL.\nThis enables schema provisioning on the real Supabase instance.",
        "priority": "Critical",
        "relevant_files": [
          "12-operations.md (Section 3.1)",
          "02-foundation-db.md (Section 8)"
        ],
        "relevant_flows": [],
        "definition_of_done": "`make migrate-cloud ENV=dev` successfully applies migrations to the remote database.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement RunPod IAM Provisioner",
        "actor": "AI",
        "description": "Create `scripts/provision-runpod-iam.sh`. \n1. Read `RunPodUserArn` from `stack-outputs.json`.\n2. Use `aws iam create-access-key` for that user.\n3. Push `AccessKeyId` and `SecretAccessKey` to SSM (`/{env}/runpod/aws_access_key_id`, etc.) as SecureStrings.\n4. Output a success message (do not log keys).",
        "priority": "High",
        "relevant_files": [
          "04-sam-template.md (Section 6)",
          "13-human-setup.md (Phase 4)"
        ],
        "relevant_flows": [
          "FCST-001"
        ],
        "definition_of_done": "Script runs, creates keys, and populates SSM without leaking secrets to stdout.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Execute Cloud Provisioning Sequence",
        "actor": "HUMAN",
        "description": "Run the full provisioning pipeline for the `dev` environment: 1. Ensure AWS credentials are active (`aws sts get-caller-identity`). 2. Run `make deploy-cloud ENV=dev` (creates buckets). 3. **CRITICAL**: Run `scripts/upload-weights.sh --bucket $(grep FORECAST_BUCKET .env.cloud | cut -d= -f2) --mock` (or upload real weights). 4. Run `make migrate-cloud ENV=dev`. 5. Run `scripts/provision-runpod-iam.sh`. 6. Verify `curl $(cat .env.cloud | grep API_ENDPOINT)/health` returns 200 OK.",
        "priority": "Critical",
        "relevant_files": [
          "12-operations.md"
        ],
        "relevant_flows": [
          "API-003",
          "FAIL-013"
        ],
        "definition_of_done": "CloudFormation stack is CREATE_COMPLETE. Database schemas are applied. API Health check passes.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      }
    ],
    "status": "unprocessed",
    "phase_completed_at": null,
    "phase_verification": null
  },
  {
    "title": "Phase 13: Traceability & Go-Live",
    "description": "Perform the final audit and handoff. Run a script to verify that every Flow ID (e.g., `WPLC-001`) from `99-traceability-matrix.md` is cited in the codebase comments. Configure the production CloudWatch alarms (Dead Man's Switch). Definition of Done: Traceability report confirms 100% flow coverage, alarms are active, and the system is formally marked as Live.",
    "subItems": [
      {
        "task": "Implement Traceability Audit Script",
        "actor": "AI",
        "description": "Create `scripts/audit_traceability.py`. This script must perform a two-pass verification to ensure architectural compliance.\n1. Parse `99-traceability-matrix.md` to extract the master list of required Flow IDs (e.g., `WPLC-001`, `NOTIF-003`).\n2. Recursively scan all `.go` and `.py` source files for comment tags matching `(?i)(?:Flows?|Trigger):\\s*([A-Z]{2,5}-[0-9]{3})`.\n3. Calculate the difference (Required - Implemented). If missing flows > 0, exit with status 1. Generate a detailed breakdown at `reports/traceability_audit.md`.",
        "priority": "Critical",
        "relevant_files": [
          "99-traceability-matrix.md (Section 2)"
        ],
        "relevant_flows": [],
        "definition_of_done": "Running the script generates the report. Removing a flow tag from a known file causes the script to fail.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement Security Audit Targets",
        "actor": "AI",
        "description": "Update `Makefile` with a `audit-security` target. This must run static analysis tools to generate compliance artifacts:\n1. Go: `gosec -fmt=json -out=reports/security-go.json ./...`\n2. Python: `bandit -f json -o reports/security-python.json -r worker/ runpod/`\nEnsure these tools are installed or run via Docker containers to maintain environment consistency.",
        "priority": "High",
        "relevant_files": [
          "12-operations.md (Section 7.1)"
        ],
        "relevant_flows": [
          "SEC-005"
        ],
        "definition_of_done": "`make audit-security` passes and generates JSON reports in the `reports/` directory.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement Configuration Integrity Auditor",
        "actor": "AI",
        "description": "Create `scripts/audit-ssm-config.sh`. This script verifies that the production environment is fully configured and contains no bootstrap placeholders.\n1. Accept `--env` flag.\n2. Recursively list all SSM parameters under `/{env}/watchpoint/`.\n3. Assert that NO parameter value equals `pending_setup`, `placeholder`, `change_me`, or is an empty string.\n4. Exit 1 if any invalid config is found.",
        "priority": "Critical",
        "relevant_files": [
          "13-human-setup.md (Phase 4)",
          "03-config.md (Section 4)"
        ],
        "relevant_flows": [],
        "definition_of_done": "Script runs against the target environment. Inserting a dummy `pending_setup` param causes the script to fail.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement Alarm Priming Script",
        "actor": "AI",
        "description": "Create `scripts/prime-alarms.sh`. The Dead Man's Switch alarms (`OBS-001`, `OBS-002`) trigger on *missing* data (`TreatMissingData: Breaching`). This script must manually push a 'Heartbeat' to CloudWatch to transition them to OK state immediately after deployment.\n1. Execute `aws cloudwatch put-metric-data` for Namespace `WatchPoint`.\n2. Metric `ForecastReady`, Value `1`.\n3. Dimension `ForecastType=medium_range` AND `ForecastType=nowcast`.",
        "priority": "Critical",
        "relevant_files": [
          "04-sam-template.md (Section 7.2)",
          "12-operations.md (Section 4.1)"
        ],
        "relevant_flows": [
          "OBS-001",
          "OBS-002"
        ],
        "definition_of_done": "Running the script results in the CloudWatch Alarm state transitioning from `INSUFFICIENT_DATA` or `ALARM` to `OK` within 2 minutes.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Implement Deployment Verification Suite",
        "actor": "AI",
        "description": "Create `scripts/verify-deployment.sh` to perform final sanity checks on the live deployment.\n1. **Version Check**: Compare local git tag (`git describe --tags --always`) against the remote API version (`curl $API/health | jq .version`). Fail if mismatch.\n2. **Alarm Check**: Query `aws cloudwatch describe-alarms --alarm-name-prefix watchpoint-`. Assert all `StateValue` are `OK`. If `INSUFFICIENT_DATA`, wait/poll for 60 seconds (allowing Priming to take effect). Fail if any remain non-OK.",
        "priority": "Critical",
        "relevant_files": [
          "12-operations.md (Section 4)"
        ],
        "relevant_flows": [],
        "definition_of_done": "Script passes against a healthy deployment. Fails if an alarm is manually set to error state.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Configure External Monitoring",
        "actor": "HUMAN",
        "description": "Manually configure an external uptime monitor (e.g., UptimeRobot, Pingdom) to poll the production API Health Endpoint (`/v1/health`).\n1. Target: `https://api.watchpoint.io/v1/health` (or CloudFront equivalent).\n2. Expect: HTTP 200.\n3. Frequency: 1-5 minutes.\nThis covers the 'Total AWS Region Failure' scenario where CloudWatch alarms would not fire.",
        "priority": "High",
        "relevant_files": [
          "12-operations.md (Section 4.2)"
        ],
        "relevant_flows": [
          "FAIL-013"
        ],
        "definition_of_done": "External monitor is active and reporting 'Up'.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      },
      {
        "task": "Generate Master Go-Live Report",
        "actor": "AI",
        "description": "Create `scripts/generate-golive-report.sh`. This script orchestrates the final release certification.\n1. Runs `audit_traceability.py`.\n2. Runs `audit-ssm-config.sh`.\n3. Runs `verify-deployment.sh`.\n4. Runs `make audit-security`.\n5. Aggregates all outputs into a summary file `GO_LIVE_REPORT.md` including the Git Commit Hash, Timestamp, and Pass/Fail status of each gate.\n6. If all pass, creates a git tag (e.g., `release-v1.0.0-{timestamp}`).",
        "priority": "Critical",
        "relevant_files": [],
        "relevant_flows": [],
        "definition_of_done": "Running the script produces a markdown report and (if successful) pushes a new tag to the repository.",
        "status": "unprocessed",
        "reports": [],
        "started_at": null,
        "completed_at": null,
        "satisfaction_iterations": null,
        "skip_reason": null
      }
    ],
    "status": "unprocessed",
    "phase_completed_at": null,
    "phase_verification": null
  }
]